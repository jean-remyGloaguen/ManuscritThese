%\documentclass[twoside,openright,a4paper,11pt]{book}
%
%\input{../packageFR}
%\input{../packageStyle}	
%
%
%\begin{document}

\chapter{Comment réaliser des scènes sonores réalistes ?}

L'utilisation de la NMF permet d'obtenir une estimation du niveau sonore du trafic. Mais son utilisation directe sur des enregistrements sonores (où le niveau sonore du trafic réel est inconnu) ne permet pas de connaitre son efficacité. En effet comment interpréter l'estimation du niveau sonore puisque que le niveau sonore réel est lui-même inconnu ?  La solution revient alors à simuler des scènes sonores urbaines où la contribution du trafic routier sera connue et où les estimations des niveaux sonores proposées par la NMF pourra être comparer aux solutions exactes. La problématique est alors la suivante : comment composer des mixtures sonores urbaines aussi réalistes que des enregistrements sonores ?  \\

%La question de la simulation de scènes sonore peut s'élargir à celui de la simulation et de la synthèse sonore, domaine d'étude visant à recréer des sons et des environnements sonores à partir de sons artificiels ou pré-existants. Plusieurs approches sont possibles comme
%
%\begin{itemize}
%\item la synthèse par algorithme où les signaux sonores sont modifiés à l'aide de d'outils comme la modulation en fréquence ou en amplitudes ou encore par distorsion de phase, 
%\item la synthèse par modélisation de signaux qui visent à reproduire les sources sonore présentes à partir d'élément simple (comme la décomposition d'un signa en série de Fourier), elle comprend surtout la synthèse sonore additive 
%\item la synthèse par modélisation physique où le comportement physique de la source sonore est calculé à partir de ces propriétés mécaniques et en résolvant, par exemple, l'équation de propagation associé. 
%\item la synthèse par échantillons qui vise à utiliser des échantillons sonores. Cette approche comprend la synthèse granulaire ou par table d'onde. \\
%\end{itemize}
%
%Les premières recherches sur la manipulation des sons remontent au milieu du XX\ieme siècle dans le milieu musical où des musiciens et scientifiques comme Pierre Schaffer ou Jean-Claude Risset ont développer des outils afin d'élargir le langage musical. Ces outils se sont ensuite étendu au domaine de la télécommunication (via la modulation en fréquence et en amplitude) ou bien encore dans le monde audio-visuel(cinéma, jeux vidéo) (REF) pour immerger au mieux le spectateur dans un univers.\\

\section{Création de scènes sonores : une revue de l'état de l'art}

Créer des environnements sonores urbains dépasse le cadre de la séparation de sources. 
Dans le cadre de l'étude des environnement sonores urbain ou la perception des citadins est étudié, des phases d'écoutes sont réalisées. Ces écoutes peuvent êtes fait direcement \textit{in situ} \cite{adams_soundwalking_2008} \cite{raimbault_ambient_2003}, dans la rue ou bien en laboratoire. Dans ce dernier cas, l'auditeur peut écouter soit des enregistrements audio \cite{guastavino2005ecological} soit des mixtures sonores issues d'un processus de simulation \cite{lafay_new_2014}. Si la réalisation de \textit{soundwalks} ou l'écoute d'enregistrements audio permettent indéniablement d'avoir une validité écologique, elles n'offrent pas un cadre contrôlé où la présence des sources sonores, leur niveaux sonores pourraient être choisis et modifiés. Il est donc utile de savoir modéliser de tel environnement malgré sa complexité. En effet, l'environnement sonore urbain est un milieu extrêmement variables à la fois temporellement (à un endroit donné, les sources sonores varient constamment) et spatialement (d'un quartier à un autre, les sources ne sont pas les mêmes). Simuler ces ambiances de manière suffisamment réaliste pour être assimilable à des enregistrements faits en ville n'est donc pas trivial. 


\subsection{L'auralisation d'ambiances sonores urbaines}
Une des premières approches possible est d'utiliser les techniques d'auralisation pour un environnement sonore urbain \cite{forssen2009auralization}. Cette méthode vise à restituer un signal sonore en un point en prenant en compte l'environnement spatial et les modifications qu'il apporte sur ce signal sonore. Cette méthode est couramment utilisée en acoustique du bâtiment. Dans ce domaine, on réalise la convolution entre la réponse impulsionnelle de la salle, obtenue par des mesures réalisée directement dedans si la dite-salle est déjà existante ou bien encore à partir de la modélisation de celle-ci par un logiciel (CATT-acoustics, Odeon), avec un signal sonore, enregistré dans une salle anéchoïque ou bien synthétisé. L'effet de la pièce (réverbération, diffusion) sur la restitution du son en un point donné peut alors être écouté \cite{vorlander2007auralization}.\\

Dans le cas d'un environnement sonore urbain, cette méthode présente l'intérêt de prendre en compte, sur l'ensemble d'un quartier, l'architecture des bâtiments et l'évolution temporelle des sources sonores. Mais si l'approche reste la même que dans le cas de l'acoustique du bâtiment, la tâche est plus complexe tant sur les phénomènes de propagation qui entrent en jeux que sur la modélisation des multiples sources sonores. La modélisation des phénomènes de propagations du son dans un milieux urbains est complexe car de nombreux phénomènes interviennent : dispersion géométrique, atténuation atmosphérique, effets météorologiques, effets des sols, des façades et des objets urbains (réflexion, absorption et diffusion). La modélisation des phénomènes de propagation acoustique dans un milieu urbain, si elle a fait l'objet de nombreux travaux \cite{embleton1976outdoor} \cite{embleton1996tutorial} \cite{lihoreau2006outdoor}, reste à l'heure actuelle une thématique toujours à l'étude afin d'offrir de meilleurs outils prédictifs \cite{leroy_uncertainty_2010}  \cite{guillaume_numerical_2015} et prendre en compte l'évolution architectural des villes (végétalisation des bâtiments par exemple \cite{guillaume:hal-01061125}). 

Enfin la multitude de sources sonores présentes (voitures, bus, voix, bruits de pas, oiseaux, fontaines \dots) ainsi que leur variabilité temporelle rend leur synthèse sonore complexe.

Celle des véhicules, notamment à motorisation thermique, a fait l'objet d'études permettant de mieux connaitre les sources d'émission qui lui sont indu (bruit de roulement, de moteur, aérodynamique) et qui sont variables au cours du temps (accélération, freinage). La synthèse des autres sources 


Plusieurs outils existent néanmoins et qui permettent d'écouter un environnement sonore auralisé : 

\begin{itemize}
\item
\item \textit{MithraSON} du CSTB qui propose de générer des scènes sonores à partir de synthèse granulaire. Les sources sonores liées au trafic sont générés en temps réel par le logiciel là où l'ensemble des autres sources sonores sont basées sur des enregistrements audio. 
\end{itemize}


Enfin, ces méthodes nécessitent des ressources numériques important pour mener les calculs. 

Ainsi, même si les résultats permettent une forte immersion grâce à la spatialisation du son mais aussi par l'aspect visuel à l'environnement  grâce à l'ajout de modèle 3D qui permettent l'auditeur de se \og balader \fg{} dans l'environnement urbain \cite{stienen2015auralization}, les résultats restent pour le moment trop factices pour être assimilables à des enregistrements sonore urbains.

\subsection{Composition de scènes sonores}

Une autre approche pour simuler les environnements sonores urbains, proposée par M. Schafer \cite{schafer1993soundscape}, consiste à les considérer comme la superposition d'évènements sonores distinctifs sur un bruit de fonds sonore continu. Un processus additif permet alors de créer des mixtures sonores en combinant des sons brefs (de 1 à 20 secondes) à des sons plus long (plusieurs minutes) dont les propriétés acoustiques ne varient pas dans le temps. Le défi est alors de disposer de signaux sonores suffisamment différent pour pouvoir recréer la diversité de cet environnement. L'outil TAPESTRA \cite{misra_musical_2007} se base sur l'extraction de signaux sonores issu d'enregistrements et de leur modulation afin de les insérer dans des mixtures sonores. Les scènes sont alors créées par un processus en trois parties : 

\begin{itemize}
\item un analyse de phase où des évènements sinusoïdaux, transitoires et le bruit de fond sont séparés d'un enregistrement audio. Les évènements sinusoïdaux sont sélectionné à partir d'une représentation temps-fréquence du signal. En fixant des fréquences limites et une amplitude seuil, les évènements sont extraits du signal; les régimes transitoires sont extraits à partir des variations d'énergies brusques du signal dans le domaine temporel. Enfin le bruit de fond est le signal résiduel restant après l'extraction des évènements sonores.
\item Une phase de synthèse où chaque signal extrait est modifié. Pour les sons sinusoïdaux, ces modifications peuvent être fréquentielle en multipliant les fréquences des spectres par un facteur ou bien temporelle en modifiant sa durée (allongement, troncature...). Les signaux en régime transitoire peuvent être aussi modifié en hauteur et en durée à l'aide d'un vocoder de phase. Quant au bruit de fond, le choix est fait de générer un nouvel audio similaire à un des audio extraits, à partir d'un algorithme d'apprentissage en arbres d'ondelettes. 
\end{itemize}  

Les audio modifiés peuvent alors être placé dans une scène sonore soit de manière bouclé, c'est-à-dire qu'un évènement sonore sera placé $n$ fois dans un intervalle de temps, soit plus précisément en situant temporellement son emplacement superposé à un bruit de fond.\\ 

Ces techniques présentent l'avantage notamment se s'appuyer sur des sons réelles issus directement d'enregistrements sonores et non des sons synthétisés. 

Si cette technique offre de nombreuses possibilité, notamment à partir de pouvoir modifier à l'infini les sons extraits ou d'avoir une grande maitrise dans la construction des scènes sonores, cette technique est limitée par la phase d'extraction. En effet, les évènements sonores doivent soit avoir un rapport $signal/bruit$ élevé ou bien ne pas présenter de recouvrement temporel et fréquentiel avec d'autres sources sonores. Sans cela, l'extraction des signaux est moins performante. Dans le cas d'un milieu sonore urbain, de nombreuses sources sonores présentent du recouvrement et rendent donc l'utilisation de cette méthode difficile. De plus, si pour la création de contenu musicaux savoir modifier des sons est utile, dans le cas de sons urbains, cette modification peut générer des artefacts qui viendraient rendre les mixtures sonores peu réaliste et dénaturés. \\

D'autre simulateurs se base sur des bases de données de sons pré-existantes comme chez Davies \cite{bruce_development_2009}. Leur outil fonctionne sur la superposition d'évènements sonores sur un bruit de fond. Dans leur étude, la base de son utilisée est constitué d'enregistrements des classes de sons qui ont été définies par un panel d'auditeurs comme prépondérantes à la création des ambiances sonores urbaines. Cette approche était justifiée par l'objectif de leur étude qui visait à étudier l'environnement sonore urbain et l'influence de la présence des classes de sons. Ici, puisqu'on souhaite simuler des enregistrements sonores réalisés en ville, on s'attarde à établir un ensemble plus exhaustif des classes de sons présentes. Pour cela, des enregistrements réels sont étudiés afin de savoir quelles sont les sources sonores présentes qui permettront de simuler correctement des mixtures sonores urbaines.
Afin de conserver la présence de sons réels dans les mixtures sonores tout en s'affranchissant de ces contraintes, le choix est fait d'utiliser le simulateur web \textit{SimScene}.

\section{Présentation de \textit{simScene}}
Le logiciel \textit{SimScene} \cite{rossignol_simscene:_2015} est un simulateur de scènes sonores \footnote{projet open-source disponible à \url{https://bitbucket.org/mlagrange/simscene}} qui consiste à superposer des \textit{évènement} sonore, issus d'une base de données de sons isolés, à une signal \textit{bruit de fond} qui dure tout le long de l'échantillon. A la différence de l'outil TAPESTRA, la base de données est constitué de sons isolés et non plus à partir d'une phase d'extraction. Cette particularité permet d'avoir une grande liberté quant aux sources sonores qu'on peut intégrer. \textit{simScene} permet de renseigner plusieurs paramètres pour réaliser des mixtures sonores : 

\begin{itemize}
\item le rapport \textit{évènement/bruit de fond} (abrégé SNR pour \textit{Signal Noise Ratio}),
\item le temps de présence moyen d'une classe de son,
\item l'occurrence moyenne d'une classe de son dans une scène, 
\item l'intervalle temporel entre chaque audio d'une même classe de son,
\item la présence d'un \textit{fade in} et d'un \textit{fade out} pour chaque échantillon.\\
\end{itemize}

Chaque paramètre est également complété par un écart-type permettant d'instaurer de la variabilité entre les scènes simulées. En plus d'un audio pour la mixture sonore, un audio pour chaque classe de son présent dans la scène est généré permettant de connaitre sa contribution exacte. Dans notre cas, ce sont toutes les classes de sons relatifs au trafic routier qui nous intéressent et qui permettent d'estimer son niveau sonore exact dans la scène.\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=.7\textwidth]{./figures/SimScene/exempleSimScene_spectrogramme_sourcesSonores.pdf}
\caption{Scène créée sous \textit{SimScene}. \`A gauche, le spectrogramme du signal global composé de trois sources (une voiture, un klaxon, un oiseau), à droite les spectrogrammes des trois sources audio utilisées}
\end{figure}


En parallèle, \textit{SimScene} génère 3 fichiers images (l'évolution temporelle du niveau sonore, le spectrogramme et un \textit{piano Roll} pour visualiser la répartition dans le fichier de chacune des classes, figure \ref{fig:somefiglabel}), un fichier texte résumant les temps de présence de l'ensemble des sons présents dans la scène et un fichier .\textit{mat} où se trouve la totalité des résultats et des paramètres de la scène.\\


\begin{figure}[ht]
\includegraphics[width=5cm]{./figures/SimScene/exempleSimScene2-timeDomain.png}\hfill
\includegraphics[width=5cm]{./figures/SimScene/exempleSimScene2-pianoRoll.png}\hfill
\includegraphics[width=5cm]{./figures/SimScene/exempleSimScene2-spectrum.png}
\caption{Représentation temporelle (à gauche), \textit{Piano Roll} (au centre) et spectrogramme (à droite) générés par \textit{SimScene}.}\label{fig:somefiglabel}
\end{figure}

La génération de scènes sous \textit{SimScene} peut se faire selon 2 modes. Dans le mode \textit{abstract}, l'utilisateur renseigne lui-même les échantillons sonores présents dans la scène et chaque paramètre permettant de créer des scènes complètement artificiels. \`A l'inverse, dans le mode \textit{replicate}, le schéma de la scène s'appuie sur un fichier texte où la position d'évènements sonore (début et fin) et leur classe de son correspondante sont détaillées. Ce mode permet de reproduire des scènes réelles annotées où la position de chaque évènement est connue.\\

Si \textit{SimScene} offre de nombreux paramètres pour créer de multiples scènes sonores variées, il nécessite d'avoir une base de données de sons isolés devant être suffisamment exhaustive. De plus, la qualité des audio doit être suffisante pour que la juxtaposition des sons ne viennent pas détériorer le rendu final (rapport Signal/Bruit élevé, échantillonnage à 44,1 kHz). Afin de réaliser au mieux des scènes sonores urbaines, des enregistrements sonores urbains sont étudiés. Ils permettent de connaitre les différentes ambiances sonores qui sont susceptibles d'exister en ville ainsi que les sources sonores qui les composent et enfin d'extraire les paramètres que \textit{SimScene} requiert (niveaux sonores, nombre d'occurrence d'une classe de son) pour réaliser des mixtures sonores en mode \textit{abstract} et les annotations nécessaire pour le mode \textit{replicate}. \\

\section{Études des scènes sonores urbaines}
\subsection{Présentation des scènes \textit{GRAFIC}}

Des enregistrements audio d'environnements sonores, réalisés dans le cadre du projet GRAFIC \cite{aumond_modelling_2017}, ont été récupérés. Ces audio ont été enregistrés à pied dans le 13\ieme~arrondissement de la ville de Paris sur un parcours comprenant 19 points d'arrêts (Figure \ref{fig:parcoursGRAFIC}). Le parcours définit présente l'avantage de couvrir plusieurs ambiances sonores représentatifs d'un environnement sonore urbain (Tableau \ref{tab:resume19pts}).\\
 
\begin{figure}[hbtp]
\centering
\includegraphics[width=.7\textwidth]{./figures/grafic/trajet_19pts.png}
\caption{Parcours réalisé par l'étude avec les 19 points de mesures avec le niveau sonore mesuré équivalent}
\label{fig:parcoursGRAFIC}
\end{figure}

Ce parcours a été réalisé sur deux jours (le 23/05/2015, jour 1, et le 30/05/2015, jour 2), deux fois par jour (le matin puis l'après-midi) dans un sens (d'est en ouest, EW) et dans l'autre (ouest en est, WE). L'enregistrement est réalisé par un système d'acquisition équipé d'un microphone ASASense omnidirectionnel situé sur un sac à dos porté par l'opérateur. En tout, 76 enregistrements audio de 1 à 4 minutes sont disponibles. \\

\input{tab/tab_resume_19_points_mesures}


\subsection{Écoutes des scènes sonores}

La première étape établit un classement des enregistrements à partir des indications fournis dans \cite{aumond_modelling_2017} (résumé dans le Tableau \ref{tab:resume19pts}) et des écoutes faites selon quatre ambiances sonores (\textit{parc}, \textit{rue calme}, \textit{rue animée}, \textit{rue très animée}) comme défini par \cite{can_describing_2015} (Tableau \ref{tab:classificationScene}).\\

\input{tab/tab_classification_scene_sonore}


Une majorité de scènes appartiennent à l'ambiance sonore \textit{rue calme} (36 scènes), 22 scènes appartiennent à l'ambiance \textit{rue animée} et 8 scènes à l'ambiance \textit{parc} et \textit{rue très animée}. Plus de la moitié des points de mesures possèdent la même ambiance sur les 4 trajets. A l'exception du point 10, les autres points de mesures possèdent deux ambiances sonores voisines. Ces variations peuvent provenir des variations d'activité dans la journée (matin ou l'après-midi). Enfin, les points 3 et 19 du parcours 1-WE ne sont pas exploitables : le point 3 est pollué par un camion balayeur et le point 19 n'a pas été correctement enregistré. Au final, c'est 74 fichiers audio qui sont disponibles. 

\subsection{Annotation}\label{part:scene_annotation}

L'annotation des enregistrements est ensuite réalisée. Il consiste à écouter chaque fichier audio et à estimer les sources sonores présentes ainsi que leur temps de présence (exemple en Tableau \ref{tab:exemple_annotation}). Pour chaque enregistrement, un fichier .txt résume ces informations.\\

\begin{table}[t]
\centering
\begin{tabular}{lll}
\textbf{évènements}    & $\mathbf{t_{init}}$ \textbf{(s)} & $\mathbf{t_{fin}}$ \textbf{(s)} \\ \hline
bruit rue     & 0,00            & 8,50           \\ \hline
voix          & 0,00            & 44,00          \\ \hline
camion        & 1,00            & 56,10          \\ \hline
voix          & 36,50           & 42,30          \\ \hline
voiture Ville & 52,00          & 63,00          \\ \hline
voix          & 59,00           & 66,50         
\end{tabular}
\caption{Exemple d'un fichier d'annotation pour la scène 1-EW-07}
\label{tab:exemple_annotation}
\end{table}


De ces annotations, il est alors possible d'estimer par ambiance sonore, un niveau sonore moyen, les classes de son qui caractérisent leur bruit de fond et également les classes de sons catégorisé en évènements sonores et leur densité (nombre d'évènement par minute). Ces informations sont alors suffisante pour pouvoir recréer ces scènes par le mode \textit{abstract} de \textit{SimScene} (Tableau \ref{tab:obsScene}). \\

\input{tab/tab_occurence_source_par_ambiance}

Sur l'ensemble des scènes sonores, XX classes de sons sont identifiés : . La classe de son \textit{bruit rue} résume les nombreux bruits, le plus souvent très bref, dont la source sonore n'a pas pu être déterminée. De la même façon, les sons relatifs à un chantier en construction (marteau-piqueur, marteau, perceuse) sont regroupés en une seule classe par soucis de simplification. Les sources sonores les plus communes sont \textit{voiture}, \textit{voix} et \textit{bruit rue}. En outre, en plus des classes de sons résumées dans le Tableau \ref{tab:obsScene}, de nombreuses autres classes de sons (\textit{aboiement de chien},\textit{bruit de balais}, \textit{toussotement}, \textit{passage d'avion}, \textit{roulement de valise}) entendus interviennent plus sporadiquement (nombre d'évènement/min < 0,1) et sont susceptibles d'intervenir dans les quatre ambiances sonores.

On observe une évolution générale des classes de son avec l'augmentation du niveau sonores des ambiances : plus la rue est bruyante plus la part de la classe \textit{trafic} et celles de l'activité humaine (\textit{voix, bruit de pas}) sont prédominantes. À l'inverse, les classes de sons \og naturel \fg{} (\textit{oiseaux)} disparaissent progressivement.

Notons que dans \textit{rue calme}, \textit{bruyante} et dans \textit{parc}, le décompte des voitures est assez aisé, il l'est moins dans \textit{rue très bruyante} où c'est plus un flot, parfois continu, de véhicules qui est présent, le comptage y est alors très délicat car les véhicules peuvent être considérés à la foi comme bruit de fond et évènements sonore. Ainsi, lorsque le flux de véhicule est trop important, on considère en moyenne 1 véhicule par seconde. Ce nombre est donc soumis à une forte incertitude mais reste cependant cohérent avec les indications du débit moyen fournis dans \cite{aumond_modelling_2017}.\\

Ces observations (ambiances sonores, classes de sons présents par ambiance, débit de voiture) et ces annotations permettent ensuite de réaliser des mixtures sonores urbaines respectivement avec le mode \textit{abstract} ou avec le mode \textit{replicate}. Le relevé des différentes classes de sons sert ensuite à générer une base de données de sons afin réaliser des scènes.

\section{Création d'une base de données}

\subsection{Constitution des évènements et des bruits de fond sonores}

La base de données de sons pour \textit{SimScene} comprend un ensemble de classes de sons isolés (oiseaux, voiture, klaxon  \dots) qui contiennent chacune plusieurs échantillons (\textit{oiseaux01.wav}, \textit{oiseaux02.wav} \dots) pour permettre une grande variabilité dans les mixtures sonores créées. La plupart des échantillons sont trouvés sur des sites en ligne de sons \footnote{\url{www.freesound.org}} \footnote{\url{www.universalsoundbank.com}} et à l'aide de la base de données constituée par J. Salamon et al. \cite{salamon_dataset_nodate}. Leur base de données comprend en tout plus de 8000 fichiers audio, collectés également sur le site \textit{freesound.org}, d'une durée inférieure à 4 secondes répartit en 10 classes de sons : ventilation, klaxon de voiture, enfants qui joue, chien qui aboie, sonnerie, moteur en fonctionnement, coup de feu, marteau-piqueur, sirène et musique dans la rue. L'ensemble des échantillons a été trié afin de ne conserver que les audio ayant un rapport signal à bruit grand et un échantillonnage de 44,1 kHz minimum.\`A partir de la liste des noms des fichiers originaux fournis avec cette base de données, les fichiers audio sont récupérés dans leur intégralité sur le site internet et intégrés dans la base de données.\\
Afin d'obtenir un rapport signal à bruit acceptable, certains audio ont été filtrés à l'aide du logiciel d'Audacity par un filtre de Wiener. D'autres signaux ont, quant à eux, été tronqués ou bien divisés en plusieurs fichiers afin d'obtenir des durées convenables. 
 
\subsection{Enregistrements de passages de véhicules}
S'il est possible de trouver l'ensemble des classes de son dans une qualité suffisante en ligne, dans le cas de la classe \textit{voiture}, il nous a semblé utile de réaliser des enregistrements de passages de véhicules sur une piste d'essai afin de posséder un ensemble varié et maitrisé de vitesses et de modèles de véhicules. Pour cela, 4 voitures ont été testé (Renault Mégane, Renault Clio, Renault Sénic et Dacia Sandero) en suivant un plan de mesure comprenant plusieurs vitesses stabilisées pour différents rapports de vitesses et en phase d'accélération et de freinage.
Photo et moteur ??

\input{tab/tab_plan_vitesse_voiture}

Les enregistrement ont été réalisé sur la piste d'essais de l'Ifsttar de Nantes le 7 et 8 juillet 2016 à l'aide du système d'acquisition A COMPLETER, la position du microphone a respecté la norme A COPLETER et fut donc situé à 7m de la piste à une hauteur de 1m50. Enfin, les conditions météorologiques étaient satisfaisantes (temps clar et dégagée, température à l'ombre de 25$/°$ C , vitesse moyenne du vent inférieure à 2 m/s). Les enregistrements sont ensuite extraits en fichiers audio en format .wav échantillonnés à 44,1 kHz.
 
En raison de la présence d'arbres situés proche de la piste, de nombreux oiseaux ont été enregistrés détériorant la qualité des fichiers audio. Afin d'atténuer leur présence, un filtre médian a été appliqué sur leur spectrogramme \cite{fitzgerald_drum_2010} dans la bande de fréquence $\left[2500 - 6500\right]$ Hz, correspondante aux fréquences d'émission des oiseaux. Ce filtre consiste a définir une fenêtre et à attribuer la valeur médiane de cette fenêtre à l'élément central. Puisque les aspects à la fois temporel et fréquentiel sont à prendre en compte, le fenêtre du filtre est de forme rectangulaire de taille $5 \times 9$ (96 Hz $\times$ 230 ms).\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=.9\textwidth]{./figures/autres/filtrageMedian_VL1_R3_40_FR.pdf}
\caption{Zoom du spectrogramme (fenêtre $W = 2^{12}$, $nfft = 2^{12}$, overlapping = 50 $\%$) dans la bande de fréquence $\left[1500-7500 \right]$ Hz d'un enregistrement de passage de véhicule (véhicule Renault, rapport 3, 40 km/h). \`A gauche, l'enregistrement original, à droite l'enregistrement filtré par le filtre médian.}
\end{figure}


La présence des oiseaux est alors fortement atténué (même si elle reste, sur certains enregistrements, persistante) sans toutefois dégrader le passage du véhicule. Leur utilisation est donc possible sans diminuer la qualité des scènes simulées.\\

\subsection{Base de données complète}
La base de données comprend alors des évènements sonores court allant de 1 secondes (klaxon, aboiement de chien) à plusieurs dizaines de secondes (passages de voiture, sirènes d'ambulances). Ces éléments permettent de créer du dynamisme sonore dans la scène et sont les évènements sonores qu'on peut annoter dans une scène. Elle comprend également des sons de durées plus longues (1 min à 2 min) qui vont permettre de générer une bruit de fond sonore utile à la création de l'ambiance sonore générale de la scène (oiseaux, voix d'enfant dans une cours de récréation, trafic routier continu...). Les enregistrements des passages de voitures sont séparés en deux catégories : \textit{ville} et \textit{route}. Dans la première catégorie, se trouve toutes les voitures ayant une vitesse stabilisée ou finale inférieure à 50 km/h et dans la seconde, une vitesse stabilisée ou finale supérieure ou égale à 50 km/h. L'ensemble des fichiers audio est en format .wav échantillonnés à 44,1 kHz. La base de données finales est résumée dans le tableau \ref{tab:dataBaseEv} pour les évènements sonores et dans le tableau \ref{tab:dataBaseBcg} pour les bruits de fond sonores. 

\input{tab/tab_base_de_donnee}

L'annotation des scènes GRAFIC et la base de données permettent maintenant de reconstituer ces scènes.

\section{Reproduction des scènes réelles}

Afin d'obtenir des scènes les plus réalistes possibles, le choix a été fait de reproduire les 74 enregistrements à l'aide de leur annotation et du mode \textit{replicate} de \textit{SimScene}. Ce choix permet ainsi de s'assurer que la disposition des évènements sonores dans les mixtures sonore s'est déjà produite. La difficulté réside surtout dans l'estimation du \textit{SNR} pour les évènements sonores qui doit être cohérent par rapport à l'ambiance souhaitée. Son estimation et sa variance s'est donc faite empiriquement et a été ajusté progressivement en fonction du rendu obtenu. Le niveau sonore global de la scène simulée est enfin modifié pour être similaire à celui de la scène réelle.\\

Dans la suite du document, les scènes issues du mode \textit{replicate} de \textit{SimScene} seront appelées \og scènes répliquées \fg{} en raison du processus de duplication. Les scènes originelles sont quant à elle nommées \og scènes enregistrées \fg{}.


\section{Tests perceptifs}\label{sec:test}

Afin de vérifier que le rendu global des scènes répliquées est suffisamment réaliste pour être similaire à des enregistrements faits en ville, celle-ci sont soumises à un test perceptif. Ce test consiste à faire écouter, à un panel d'auditeurs, un ensemble de scènes sonores comprenant autant d'enregistrements sonores que de scènes reconstitués. À chaque scène, l'auditeur doit alors évaluer, sur une échelle de Likert à 7 points allant de \og très peu réaliste \fg{} à \og extrêmement réaliste \fg{}, le réalisme de la scène qu'il vient d'entendre. L'objectif est que l'ensemble des scènes répliquées soient perçues de façon similaire aux scènes réalistes.\\

\subsection{Mise en place du test}
\label{sec:test_BEI}

Sur l'ensemble des 148 scènes (74 réelles, 74 répliquées),  un ensemble de 40 scènes d'une durée de 30 secondes sont testés. Cet ensemble est composé pour moitié de scènes réelles et des même scènes répliquées. L'hypothèse faite est que si les 20 scènes répliquées sont perçues de la même manière que les 20 scènes enregistrées, le réalisme peut être étendu aux 54 autres scènes répliquées. 

Dans un premier temps, 20 scènes enregistrées ont été choisis aléatoirement parmis les 74 enregistrements tout en prenant soin d'avoir une répartition équitable entre les ambiance sonores afin d'avoir suffisamment de diversité sonore. On extrait alors 5 scènes issus d'une ambiance \textit{Parc}, 6 issus de \textit{Rue calme}, 4 de \textit{Rue animée} et 5 de \textit{Rue très animée}  dans les échantillons. Pour chaque audio, 30 secondes sont ensuite sélectionnés aléatoirement. Puis, dans un second temps, les même 30 secondes des mêmes scènes répliquées viennent composée la seconde partie du corpus de test  (Tableau~\ref{tab:resume_scene_test}).\\

\input{tab/tab_40_audio_teste}


Un seul auditeur n'écoute toutefois pas les 40 scènes disponibles car le test serait trop long et la capacité de concentration de l'auditeur ne pourrait pas être constante tout le long du test. Ainsi, chaque auditeur écoute alors un sous-corpus de 20 audio ; la durée du test n'excède alors pas 10 minutes. 

Ces 40 audio comprennent 20 extraits de 30 secondes issus des enregistrements et les 20 mêmes extraits généré par le mode \textit{replicate} de \textit{SimScene}. 



Comme les auditeurs n'évaluent plus l'ensemble des scènes mais seulement une partie, il faut définir un plan d'écoute qui répartit équitablement l'ordre de succesion des écoutes. Pour cela, on réalise un \og Bloc Équilibré Incomplet \fg{} (BEI) \cite{pages_blocs_2007}. \\


En analyse sensorielle, un BEI permet d'élaborer l'ordre d'évaluation des produits testés pour chaque panéliste en évitant que des biais statistiques apparaissent (effet de rang, du juge, de succession \dots). Il se construit à l'aide plusieurs variables :

\begin{itemize}
\item le nombre de juges $J$ (appelé aussi \textit{blocs}), 
\item le nombre de produits à tester, $B$ (appelé aussi \textit{variétés} ou \textit{traitements}),
\item le nombre de produits testé par juge, $K$
\item le nombre de réplications d'un produit, $R$
\item le nombre de répétabilités d'une paire de produit, $\lambda$.\\
\end{itemize}

Plusieurs conditions sont à remplir entre ces variables pour réaliser un BEI correct : 

\begin{subequations}\label{BIE_cond}
\begin{align}
B &\geq K, \label{eq:BIE_cond1}\\
JK &= BR, \label{eq:BIE_cond2}\\
\lambda &= R\frac{K-1}{B-1}. \label{eq:BIE_cond3}
\end{align}
\end{subequations}

avec $\left[J, B, K, R, \lambda\right] \in \mathbb{N}$.\\

La dénomination \og incomplète \fg{} provient de l'évaluation des juges que d'une partie de l'ensemble des produit à tester ($K < B$). La dénomination \og équilibré \fg{}, quant à elle, provient de la constance de $\lambda$ pour les différents couples de $B$. \\

Plusieurs paramètres ont été choisis et justifiés au début de la partie : le nombre de produit testé a été établi à 40, $B = 40$, pour un nombre de produit testé par juges fixé à 20, $K = 20$. 

La principale difficulté reste l'obtention de la participation de $J$ personnes pour ce test. Ce nombre est alors fixé à $J = 50$ en cela que ce nombre est suffisant et facilement atteignable en peu de temps.

À partir des variables $J$, $B$ et $K$, le nombre $R$ de réplication est défini à 25. Toutefois, ces valeurs impliquent que la condition \ref{eq:BIE_cond3} n'est pas validée ($\lambda = 9,69$) et donc que les contraintes que l'on s'impose ne permettent pas d'obtenir un plan équilibré. Deux solutions sont alors possibles : la première serait de modifier certains paramètres pour trouver l'équilibre. Or le nombre de juges, $J = 50$, parait un nombre limite raisonnable à atteindre ainsi que le nombre d'audio à tester, $K = 20$, pour une durée de test de 10 minutes est une forte contrainte qu'on ne souhaite pas modifier. Avec ces 2 contraintes fixées, on n'obtient pas de plan d'écoute adéquat. La deuxième solution, qui semble alors la plus adaptée, est de réaliser un plan optimal \cite{pages_blocs_2007}. Dans ce cas, pour une configuration $\left[J, K, R\right]$ données, un algorithme d'échange détermine un \og plan optimal \fg{} qui satisfait le mieux son équilibre (sans toutefois l'atteindre parfaitement).\\

Cette méthode établit dans un premier temps, le nombre de combinaison total possible ($J \times B$) puis un premier plan des combinaisons possibles (appelé $X$ de dimension $J \times K$) est élaboré de façon aléatoire. Celui-ci est ensuite mis à jour itérativement en remplaçant chaque combinaison possible $\tau_{j,k}$ par une autre combinaison $\tau^{*}_{j,b}$ extrait de la matrice de combinaison totale de telle façon à minimiser le produit matriciel \ref{eq:mini_det_BIE}. Ce procédé est le principe de l'algorithme d'échange.

\begin{equation}\label{eq:mini_det_BIE}
\underset{\tau_{j,b}}{\text{min}} \det(X'X)^{-1}.
\end{equation}

Cet algorithme est dit $D$-optimal car il fait intervenir l'opérateur \textit{D}éterminant mais il peut être $A$-optimal en faisant appel à l'opérateur \textit{Trace} à la place. Le plan optimal $X_{opt}$ en fonction des conditions $J$, $K$ et $R$ est réalisé sous le logiciel \textit{R} à l'aide la fonction \textit{optimaldesign} fourni par le package \textit{SensoMineR} \cite{le_sensominer:_2008}. Le résultat est alors un plan $X_{opt}$ de dimensions $J \times K$ résumant l'ordre d'écoutes des audio pour chaque juge. La figure \ref{fig:replication} résume le nombre de réplication de chaque scène dans le plan obtenu.\\

\begin{figure}[ht]
\centering
\includegraphics[width = 0.7\textwidth]{./figures/test_perceptif/nb_replication.pdf}
\caption{Nombre de réplication, $R$, pour chaque scène obtenu dans $X_{opt}$ avec comme combinaison $J = 50$, $B = 40$, $K = 20$. Les 20 premières scènes sont les scènes issus des enregistrements du projet GRAFIC, les 20 suivantes sont les scènes répliquées sous \textit{SimScene}.}
\label{fig:replication}
\end{figure}

L'optimisation du plan ne permet alors pas d'avoir un nombre de réplication $R$ constant mais variable évoluant dans l'intervalle $\left[20-30 \right]$. Toutefois, en moyenne, les scènes réelles et simulées sont écouté un même nombre de fois (25 fois). On s'assure ensuite que la répartition entre les scènes réels et simulées pour chaque juge est équitablement répartie (figure~\ref{fig:repartition}).\\

\begin{figure}[ht]
\centering
\includegraphics[width = .7\textwidth]{./figures/test_perceptif/repartition-real-simulated.pdf}
\caption{Répartition entre les scènes réelles et simulées par juge. La somme cumulée des deux ensembles correspond aux nombres d'écoutes $K$ qu'effectue un juge.}
\label{fig:repartition}
\end{figure}

Le plan généré permet bien d'avoir en moyenne une répartition équilibrée entre les scènes réelles et simulées, même si certain juges ont jusqu'à 12 scènes d'un même type.\\

Une page web \footnote{http://soundthings.org/research/xpRealism} est mis en ligne le 8 février 2017 permettant l'accès au test à une large public et s'est clôturé 12 jours plus tard. Chaque juge écoute donc une succession de 20 audio de 30 secondes dans un ordre établit par le plan optimal. Chaque audio peut être réécouter autant de fois que possible avant d'être évaluer sans qu'il soit toutefois possible de revenir sur son évaluation. L'auditeur a également la possibilité de laisser un commentaire sur chaque audio pour pouvoir justifier son choix. En fin de test, afin de connaitre le panel d'évaluateur, il est demandé aux juges de renseigner leur âge, leur sexe et leur expérience quant à l'écoute de mixtures sonores urbaines.\\

Les fichiers résultats sont stockés également sous une page web \footnote{http://soundthings.org/research/xpRealism/responses/} sous le format .json et sont traités sous le logiciel Matlab.\\

\subsection{Résultats}
\subsubsection{Constitution du panel}

La figure \ref{fig:panelTest} résume, sous forme d'histogrammes, l'âge, le sexe et l'expérience des auditeurs. 2 personnes ont renseigné aucun de ces champs et une troisième personne a seulement omis de préciser son sexe.\\

\begin{figure}[ht]
\centering
\includegraphics[width = .8\textwidth]{./figures/test_perceptif/testPerceptif_panel.pdf}
\caption{Résumé des informations relatifs aux panélistes}
\label{fig:panelTest}
\end{figure}

Le panel est composé à 62 $\%$ d'hommes et à 32 $\%$ de femmes. La classe d'âge $\left[20-30\right[$ est la plus représentée suivie de la classe $\left[30-40\right[$, 26 $\%$, $\left[50-60\right[$,  18 $\%$ $\left[40-50\right[$, $10\%$ et enfin de la classe $>60$,  4 $\%$ . 62 $\%$ du panel a déclaré n'avoir pas d'expérience dans l'écoute d'ambiances sonores urbaines contre 34 $\%$. Cette dernière caractéristique indique que la majorité des jugements provient d'auditeurs inexpérimentés dans ce domaine et se sont donc plus attardés sur une évaluation générale de la scène là où les auditeurs plus expérimentés se sont attardés en plus sur des aspects plus particulier comme la différence de réverbération entre les sources sonores. \\

\subsubsection{Modèle de l'ANOVA}
Une analyse de variance (abrégée ANOVA pour \textit{ANalyse Of VAriance} en anglais) est réalisée afin de savoir si la distribution des notes des scènes simulées (abrégé \textit{Si}) est similaire à celles de notes réelles (abrégé \textit{Re}) mais également pour connaitre l'influence de l'expérience de l'auditeur. N'ayant qu'une seule variable quantitative (les notes), c'est donc une ANOVA à 1 dimension qui est réalisée. Ce test statistique considère un nombre de facteur $F$ comprenant chacun un nombre $N$ de niveaux où $M_n$ observations sont réalisées dans chaque niveau. Le modèle s'exprime alors : 

\begin{equation}
y_{in} = \alpha_n + \epsilon_{in}
\end{equation}

où $y_{in}$  et $\alpha_k$ sont respectivement l'observation $i$ associé et l'effet moyen associé au niveau $j$ et $\epsilon_{in}$ est une erreur résiduelle suivant une loi normale centrée ($\epsilon_{in} \sim \mathcal{N}(0,\,\sigma^{2})$). Deux hypothèses sont alors émises sur les distributions : 

\begin{itemize}
\item les distributions des niveaux $n$ et $m$ sont semblables (hypothèse \textit{nulle} $H_0$),
\item les deux distributions sont différentes, (hypothèse \textit{alternative} $H_1$).\\
\end{itemize}

Le test statistique de Fischer détermine alors si l'hypothèse $H_0$ est vraie ou fausse (et donc si l'hypothèse $H_1$ est vérifiée). Ce test consiste à établir le rapport $\mathbf{F}$ de deux variances, 
 
\begin{equation}
\mathbf{F} = \frac{var_1}{var_2}.
\end{equation}

Le problème étant à 1 dimension, la variance totale $var_{tot}$ s'exprime comme la somme de la variance du modèle $var_{mod}$ (appelé variabilité inter-niveau) et celui d'un résidu $var_{res}$ (ou variabilité intra-niveau) : 

\begin{equation}
var_{tot} = var_{mod} + var_{res}.
\end{equation}

En considérant un nombre d'observation total $M = \sum_{k = 1}^{K} M_k$, chacune de ces variances s'exprime comme


\begin{equation}
var_{mod} = \frac{SCE_{mod}}{DDL_{mod}},
\end{equation}

\begin{equation}
var_{res} = \frac{SCE_{res}}{DDL_{res}} 
\end{equation}

avec 

\begin{itemize}
\item la somme des carrés des écarts du modèle, $SCE_{mod} = \sum_{n=1}^{N} m_n (\bar{y}_{in} - \bar{y})^2$, 
\item la somme des carrés des écarts du résidu, $SCE_{res} = \sum_{i=1}^{M_n} \sum_{n=1}^{N} (y_{in} - \bar{y}_n)^2$, 
\item le degré de liberté du modèle, $DDL_{mod} = F-1$,
\item le degré de liberté du résidu, $DDL_{res} = M-F$, 
\item $\bar{y} = $
\end{itemize}


Le rapport $\mathbf{F}$ s'exprime alors : 
\begin{align}
\mathbf{F} & = \frac{var_{mod}}{var_{res}}\\
& = \frac{\nicefrac{SCE_{mod}}{DDL_{mod}}}{\nicefrac{SCE_{res}}{DDL_{res}}}\\
& = \frac{M-F}{F-1}\frac{\sum_{n=1}^{N} m_n (\bar{y}_{in} - \bar{y})^2}{\sum_{i=1}^{M_n} \sum_{n=1}^{N} (y_{in} - \bar{y}_k)^2}.
\end{align}

Des degrés de libertés et de la valeur $\mathbf{F}$, on peut déterminer la \textit{p-valeur} (à l'aide des tables de Fischer ou à l'aide de logiciels comme \textit{R} ou Matlab) qui établit la probabilité d'obtenir une valeur limite du test si $H_0$ est vraie. Cette valeur est comparée a une seuil de signification $\alpha = 0.05$. Se présente alors deux cas :
 
\begin{itemize}
\item si $\alpha >$ \textit{p-valeur}, il existe alors au moins deux distributions différentes, l'hypothèse $H_0$ est rejetée et $H_1$ est acceptée,
\item si $\alpha <$ \textit{p-valeur}, l'hypothèse $H_0$ n'est pas considérée comme \textit{vraie} mais on considère alors qu'il n'y a pas de raison à rejeter $H_0$. Cette nuance provient du fait que cette décision se base sur un nombre limité d'informations (le nombre total d'observation $M$) qui ne permet pas de rejeter l'hypothèse $H_1$.\\
\end{itemize} 

\subsubsection{Par type de scènes}

Dans le cas du test perceptif, on considère un seul facteur ($F = 1$), le réalisme de la scènes, qui comprend deux niveaux \textit{réelles} et \textit{simulées} ($N = 2$), chaque niveaux ayant un nombre d'observation $M_n$ correspondant à l'ensemble des notes du panel appartenant à l'un des deux niveaux et un nombre totale d'individu $M = J \times K = 1000$. Une ANOVA est réalisée sous le logiciel Matlab et les résultats sont résumés dans le tableau \ref{tab:anova}.\\

\begin{table}[ht]
\centering
\begin{tabular}{lccccc}
\hline
\textbf{Source}     & \textbf{SCE} & \textbf{DDL} & \textbf{variance} & \textbf{F} & \textbf{p-valeur} \\
\hline
\textbf{réalisme} & 4.62         & 1            & 4.62              & 1.79       & 0.18              \\
\hline
\textbf{erreur}      & 2567.40      & 997          & 2.57              &            &                   \\
\hline
\textbf{total}      & 2572.00         & 998          &                   &            &       \\
\hline
\end{tabular}
\caption{Résultat de l'ANOVA calculé}
\label{tab:anova}
\end{table}


La \textit{p-valeur} est supérieure au seuil de signification $\alpha$ et est supérieur à 0.1. Il n'y a donc pas de présomption contre l'hypothèse $H_0$. On peut alors considéré qu'il n'y a pas de distinction possible entre les scènes simulées et réelles faites par le panel. \\

En plus des résultats textuels, une représentation graphique sous forme de diagramme en boîte à moustache est faite selon le type de scènes (figure \ref{fig:ANOVA_scene}). Cette représentation graphique permet de comparer plusieurs distributions en résumant pour chaque boîte la médiane (trait plein rouge), les valeurs du  premier quartile au troisième quartile (boîte en bleue), la valeur maximale et minimale de la distribution (respectivement trait supérieur et inférieur en noir). \`A cela est également ajoutée la moyenne.\\

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{./figures/test_perceptif/testPerceptif_boxplotType_FR.png}
\caption{Représentation en diagramme en boîte à moustache entre les scènes réelles et simulées}\label{fig:ANOVA_scene}
\end{figure}

La répartition des notes pour les deux type de scènes, quelque soit l'expérience de l'auditeur, est similaire. Chaque type présente des valeurs identiques (médiane, valeurs extrêmes, quantiles). Seule la note moyenne permet de différencier les deux ensembles : $m_{Re} = 4.93 \pm 1.64$ et $m_{Si} = 5.06 \pm 1.56$. Les deux valeurs sont quasiment similaires confirmant que les deux distributions sont donc bien identiques et que les scènes simulées ont un rendu similaire aux enregistrements réels. \\

\subsubsection{Par expérience et par type de scènes}
Il est possible de déterminer l'influence de l'expérience de l'auditeur dans les écoutes d'ambiances urbaines dans l'évaluation des scènes par un ANOVA (tableau~\ref{tab:anova_exp}, figure~\ref{fig:ANOVA_exp}). Il y a donc ici 2 facteurs $F$, le type de scènes et l'expérience, qui ont 2 niveaux $N$ chacun (respectivement Re/Si et expérience/sans expérience).

\begin{table}[ht]
\centering
\begin{tabular}{lccccc}
\hline
\textbf{Source}     & \textbf{SCE} & \textbf{DDL} & \textbf{variance} & \textbf{F} & \textbf{p-valeur} \\
\hline
\textbf{réalisme} & 4.62         & 1            & 4.62              & 1.79       & 0.18              \\
\hline
\textbf{expérience}    & 4.85         & 1            & 4.85              & 1.89       & 0.16              \\
\hline
\textbf{erreur}      & 2562.52      & 997          & 2.57              &            &                   \\
\hline
\textbf{total}      & 2572.00         & 999          &                   &            &       \\
\hline
\end{tabular}
\caption{Résultat de l'ANOVA calculé}
\label{tab:anova_exp}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{./figures/test_perceptif/testPerceptif_boxplotExperience_EN.pdf}
\caption{Distribution des notes selon le type de scène et l'expérience dans l'écoute des scènes sonores urbaines}\label{fig:ANOVA_exp}
\end{figure}


%\begin{table}[]
%\centering
%\begin{tabular}{p{3cm} C{3cm} C{3cm}}
%\cline{2-3}
% & \multicolumn{2}{c}{\textbf{type}} \\
%\cline{2-3}
% & \textbf{réelle} &  \textbf{simulée} \\ \hline
%\textbf{avec expérience} &  $5.13 \pm 1.60$ & $5.06 \pm 1.70 $ \\ \hline
%\textbf{sans expérience} &  $4.83 \pm 1.65$ & $5.07 \pm 1.49$ \\ \hline
%\end{tabular}
%\caption{Moyennes obtenue selon l'expérience et le type de scènes}
%\label{my-label}
%\end{table}

Si on différencie les auditeurs selon leur expérience dans l'écoute d'ambiances sonores urbaines, on constate que les auditeurs expérimentés évalue mieux les scènes réelles que les scènes simulées à l'inverse des auditeurs sans expériences. De plus, si les moyennes pour les scènes simulées sont fortement similaires quelque soit l'expérience, la notation des scènes réelles est différente. Des retours et remarques faites par plusieurs panéliste permette de supposer que les auditeurs plus expérimentés sont plus susceptibles de faire attention aux détails de la scènes (composition des évènements sonores, connaissance sur la panel de sons pouvant être présents, différence de réverbération entre les sources sonores..) rendant les scènes simulées plus identifiables. À l'opposé, les auditeurs non expérimentés vont plus s'attarder à évaluer l'ensemble de la scène. Or comme les scènes simulées sont constitué de sons qui sons isolés initialement, il est plus facile pour l'auditeur de les reconnaitre dans la scène qu'il écoute et donc de se \og  projeter \fg{} dans le milieu urbain. Dans certaines scènes réelles, les sources sonores étant moins discernables la perception du réalisme est réduite.\\

Toutefois, malgré ces faibles différences, les moyennes et les distributions restent, là encore, similaires et permettent de conclure que même avec de l'expérience dans l'écoute de scènes urbaine, la qualité des audio simulées est satisfaisante.\\

\subsubsection{Par ambiance et par scène}

On regroupe, dans la figure~\ref{fig:boxplot_ambiance}, les scènes par ambiances sonores (\textit{parc}, rue \textit{calme}, rue \textit{animée}, rue \textit{très animée}).\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=0.7\textwidth]{./figures/test_perceptif/testPerceptif_boxplotAmbianceCOLOR_EN.pdf}

\begin{tabular}{|p{1.5cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2.75cm}|l|}
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
Parc & {\cellcolor[HTML]{5AB25A}} & & Rue calme & {\cellcolor[HTML]{FFCB2F}} & & Rue animée & {\cellcolor[HTML]{F56B00}} & &  Rue très animée & {\cellcolor[HTML]{9A0000}}\\
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
\end{tabular}

\caption{Distribution en fonction de l'ambiance sonore pour les scènes réelles (en haut) et les scènes simulées (en bas)}
\label{fig:boxplot_ambiance}
\end{figure}

 
Cette représentation permet de constater que les ambiances sonores \textit{animée} et \textit{très animée}, dans les deux types de scènes, sont évaluées comme les plus réalistes : la médiane et la moyenne sont élevées avec une distribution peu dispersée. \`A l'inverse, les ambiances plus calmes (\textit{parc} et \textit{calme}) sont plus dispersés et ont une note moyenne plus faible. C'est donc les ambiances constituées en majorité du trafic qui sont les mieux évalués. Les scènes dans les parcs et rues calmes, constituées de moins de trafic et plus de sons urbains divers (voix, bruit de pas, oiseaux), sont moins bien évaluées aussi bien pour les scènes issus d'enregistrements que celles créer.\\

Enfin, pour chaque scène, la distribution des notes est établie et sont mis en relation avec les commentaires laissés par les auditeurs (figure~\ref{fig:ANOVA_scene}).\\

\begin{figure}[h]
\centering
\includegraphics[width=.9\textwidth]{./figures/test_perceptif/testPerceptif_meanPerSceneCOLOR.pdf}

\begin{tabular}{|p{1.5cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2.75cm}|l|}
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
Parc & {\cellcolor[HTML]{5AB25A}} & & Rue calme & {\cellcolor[HTML]{FFCB2F}} & & Rue animée & {\cellcolor[HTML]{F56B00}} & &  Rue très animée & {\cellcolor[HTML]{9A0000}}\\
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
\end{tabular}

\caption{Distribution par scène pour les scènes réelles (de 1 à 20) et les scènes simulées (de 21 à 40)}
\label{fig:moyParScene}
\end{figure}


Plusieurs observations peuvent être émises : 
\begin{itemize}
\item La meilleure moyenne est obtenue pour 2 scènes ex-æquo : la scène 2 (6.0 $\pm$ 1.0) et 23 (6.0 $\pm$ 1.1).
\item La plus mauvaise moyenne est réalisée pour la scène 6 (3.6 $\pm$ 1.6). C'est donc une scène issu d'un enregistrement qui a été jugé la moins réaliste. Celle-ci a la particularité de n'avoir aucun évènement sonore discernable. 
\item Parmi les 20 scènes simulées, on peut observé 4 scènes dont les moyennes sont plus faibles que les autres (scènes 22, 24, 26 et 27). Dans les scènes 24 et 26, les auditeurs ont remarqué que la présence des bruits de pas paraissent trop fort cassant le réalisme du reste de la scène. La scène 22 est, quant à elle, évaluée plus faiblement en raison d'un bruit de portail également trop fort au début de l'extrait. Ces trois scènes appartiennent à l'ambiance \textit{Parc}. La scène 27 enfin n'a pas reçu de commentaire mais sa note moyenne plus faible peut s'expliquer par un bruit de fond composé d'un nombre d'oiseaux peut être trop grand et qui parait peu réaliste dans un milieu urbain.\\
\end{itemize}

L'ensemble de cette étude met en évidence les performances de l'outil de simulation qui permet de reconstruire des mixtures sonores urbaines perçues comme suffisamment réalistes. Pour ce test, la réalisation des scènes aux ambiances rue \textit{animée} et \textit{très animée} est très correcte. Les ambiances \textit{parc} et rue \textit{calme} restent bien évalué sur leur réalisme mais sont perfectibles notamment sur certains évènements sonores, non reliés au trafic, qui détériore l'aspect réaliste des scènes. A noter, que les passages de voitures isolés ou la reconstitution du trafic n'ont pas fait l'objet de commentaire.

%\bibliographystyle{unsrt}
%\bibliography{../bibliographie}
%
%\end{document}