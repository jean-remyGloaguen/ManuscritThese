\chapter{Création de corpus de mixtures sonores urbaines}
\label{chap:corpusSonore}

\section*{\centering Résumé}

\noindent{\small \textbf{
Les étapes menant à la création des corpus de sons sur lesquelles la NMF est appliquée sont présentées. Après avoir exposé différentes méthodes pour générer un ESU, l'outil retenu pour ces travaux, le logiciel \textit{SimScene}, est décrit. La formation de la base de données de sons et les enregistrements audio de passages de véhicules sont ensuite détaillés. Le premier corpus créé, appelé corpus d'évaluation \textit{Ambiance} est présenté, celui-ci a pour objectif l'étude du fonctionnement de la NMF. Le second corpus \textit{SOUR} (Scènes sOnores Urbaines Réalistes), dont la construction est basée sur des annotations d'enregistrements audio, est ensuite exposé. Le rendu de ce corpus est évalué par un test perceptif visant à déterminer le réalisme de son rendu.}}

\vspace{2cm}

La méthode de la NMF a été retenue comme estimateur afin d'obtenir les niveaux sonores du trafic routier. Toutefois, nous choisissons de ne pas l'appliquer directement sur des enregistrements audio réalisés en ville. En effet, le trafic sonore y est alors mélangé à d'autres sources sonores. Son niveau sonore exact est alors inconnu. Il n'est donc pas possible de comparer l'estimation fournie par la méthode NMF avec une valeur de référence exacte et ainsi d'évaluer ses performances et sa justesse. L'approche choisie est ici d'appliquer cet estimateur sur des scènes sonores urbaines simulées où la contribution du trafic routier sera connue avec précision et où les estimations des niveaux sonores pourront être comparées aux niveaux exacts. Ce choix soulève plusieurs questions : comment composer des mixtures sonores urbaines aussi réalistes que des enregistrements sonores ? Comment s'assurer que les corpus de sons sur lesquels sont appliqués les algorithmes permettent de tester les limites des estimateurs ?
Il en effet nécessaire de s'attarder sur la création des mixtures sonores urbaines et sur la qualité de leur composition afin que les performances de l'estimateur soit similaires entre les scènes simulées et des enregistrements audio faits en ville.

La création d'environnements sonores urbains réalistes dépasse la question de l'estimation du niveau sonore du trafic. L'intérêt d'utiliser des scènes sonores issus d'un processus de simulation est de permettre un meilleur contrôle sur leur composition où la présence des différentes classes de sons, ainsi que leur niveau sonore, sont définis par l'utilisateur en fonction de ses besoins.
Leur utilisation trouve un intérêt dans le cadre des études perceptives des ESU et a déjà été réalisée pour, par exemple, étudier l'agrément sonore à partir de scènes sonores recréées directement par les participants et estimer l'influence de la présence des sources sonores \cite{lafay_new_2014}, ce que ne permet pas l'écoute faite en ville \cite{adams_soundwalking_2008, liu2014effects} ou en laboratoire à partir d'enregistrements audio \cite{guastavino2005ecological, cain2013development}.
Ces scènes sonores simulées peuvent également trouver un intérêt pour tester et développer des outils de traitement du signal \cite{Komatsu2016, geiger2015improving} où l'utilisation de scènes sonores simulées permet d'éviter l'étape d'annotation manuelle, qui peut être longue et fastidieuse.

Toutefois, si l'utilisation de scènes sonores simulées a de nombreux avantages, la question de leur validité écologique est importante. En effet, la réalisation de \textit{soundwalks} ou l'utilisation d'enregistrements sonore permettent de baser ces études sur des scènes sonores réelles et donc de mieux s'assurer que les outils sont bien adaptés à ces environnements.

En conséquence, il y a un intérêt certain à savoir correctement simuler des environnements sonores urbains de façon à obtenir une complexité et un réalisme suffisant, c'est-à-dire assimilable à des enregistrements faits en ville. Cette tâche reste un défi qui n'a, pour l'instant, pas été relevé et n'est pas trivial puisque l'environnement sonore urbain est un milieu extrêmement variable à la fois temporellement (à un endroit donné, les sources sonores varient constamment) et spatialement (d'un quartier à un autre, les sources ne sont pas les mêmes).
Ce chapitre décrit notre méthode de création des corpus de scènes sonores urbaines simulées. Dans une première partie, plusieurs approches permettant de simuler de tels environnements sont résumées, puis l'outil retenu est présenté en détail. Les étapes menant à la création d'une base de données, appelé corpus élémentaire, et de deux corpus d'évaluation sont ensuite exposées. On présente enfin le test perceptif et les résultats obtenus démontrant le réalisme d'un des corpus.

\section{Création de scènes sonores : choix d'une méthode}

Dans une première partie, deux approches pour réaliser des scènes sonores urbaines sont présentées : l'auralisation et la simulation de scènes sonores.

\subsection{Auralisation d'ESU}

Une des premières approches possibles pour restituer un ESU est d'utiliser les techniques d'auralisation \cite{forssen2009auralization}. Cette méthode vise à modéliser l'évolution temporelle d'un signal sonore $M_i(t)$ en un point $i$ en prenant en compte les différentes sources sonores $s_j(t)$ présentes ainsi que l'environnement spatial et les effets qu'ils génèrent sur la propagation des sources sonores $\delta_{ij}(t)$. Cette méthode équivaut à modéliser les équations \ref{eq:convolution_ESU} et \ref{eq:propagation}. En choisissant le type et le nombre de sources et l'environnement urbain, il est alors envisageable de déterminer l'environnement $M_i(t)$.
Pour cela, on réalise un produit de convolution entre la réponse impulsionnelle d'une rue, obtenue soit par sa mesure soit par sa modélisation par un logiciel (CATT-acoustics, I-Simpa \dots), avec un signal sonore, enregistré dans des conditions d'anéchoïcité ou bien synthétisé. Cette étape correspond à l'équation \ref{eq:convolution_ESU} du chapitre \ref{chap:modele}. La restitution de l'ESU et son évolution dans le temps peuvent alors être écoutés \cite{vorlander2007auralization}. Cette tâche reste toutefois complexe pour un tel environnement :

\begin{itemize}
\item La mesure de réponses impulsionnelles des rues \cite{picaut2005experimental} est une tâche complexe à réaliser puisqu'elle nécessite un dispositif expérimental conséquent qui doit être utilisé avec des conditions les plus neutres possibles (faible bruit de fond, conditions météorologiques neutres).
\item La modélisation numérique des rues est alors la voie la plus souvent choisie car elle offre plus de possibilité, mais cela nécessite tout de même de simplifier l'environnement (allure des façades, présence de petits mobiliers urbain) afin de limiter les temps de calculs.
\item Les effets de propagation du son en tenant en compte les phénomènes de diffusion, de réflexions dans un milieu urbain sont encore difficile à modéliser avec un rendu réaliste \cite{schissler2014high}.
\item La modélisation dynamique des sources sonores n'est faite que pour certaines sources sonores, comme le trafic routier ou ferroviaire, en utilisant des modèles dynamiques pour simuler leur déplacement. Ce sont alors parfois des enregistrements audio qui permettent de modéliser les autres sources sonores, ce qui permet de simplifier la modélisation mais restreint également le contrôle par l'utilisateur. 
\end{itemize}

\cite{stienen2015auralization} résument ces différents aspects, les questions soulevées et les champs d'applications que permet l'auralisation des environnements sonore urbains.
Si cette tâche reste complexe, il existe tout de même quelques outils comme le logiciel \textit{MithraSON} du CSTB qui propose de générer des ESU \footnote{extrait sonore : \url{https://www.youtube.com/watch?v=ACCV2mi81j8}}. À partir d'un quartier modélisé, les sources sonores liées au trafic sont générés en temps réel  à l'aide d'une synthèse granulaire et d'un modèle dynamique de trafic. L'ensemble des autres sources sonores (voix, oiseaux, cloche\dots) est basé sur des enregistrements audio qui sont ensuite intégrés à l'ESU. La propagation des signaux est générée à l'aide d'une méthode de tirs de rayons.
Même si les résultats permettent une forte immersion, grâce à la spatialisation du son par l'écoute binaurale, cette méthode reste complexe à implémenter et nécessite des ressources numériques importantes.

\subsection{Simulateur de scènes sonores}

Une autre approche pour simuler l'environnement sonore urbain consiste à le considérer selon une combinaison additive d'évènements sonores (ou objets sonores), $S_i$, qui enrichi un bruit de fond (ou texture  sonore), $B$ \cite{nelken2013ear} :

\begin{equation}
M(n) = \sum_{i = 1}^{N} S_i(n) + B
\end{equation}

où $n$ est un indice temporel.
La catégorie bruit de fond inclut des sons longs (plusieurs minutes) dont les propriétés acoustiques ne varient pas (ou très peu) dans le temps comme le bruit généré par un trafic continu, le chant des oiseaux dans un parc ou les voies des enfants dans une cours de récréation.
La catégorie \textit{évènement} équivaut à des sons brefs (de 1 à plusieurs secondes), répartis dans le temps, qui émergent du bruit de fond pour être perçu individuellement par un auditeur (un voiture qui passe, des bruits de pas, une sonnerie de téléphone\dots). 

Les évènements sonores $S_i$ ayant la même origine sonore sont regroupés dans une même classe de son. Par exemple, on appelle \textit{voiture}, la classe de son qui résume l'ensemble des sons qui sont générés par des voitures. 
Le défi est alors de disposer d'un nombre suffisant de classes de sons qui elles-mêmes regroupent suffisamment d'échantillons audio variés pour pouvoir recréer la diversité de l'ESU. Plusieurs outils ont été développés dans le but d'étudier la perception du paysage sonore (ou \textit{soundscape} en anglais) et l'influence de la présence des différentes source sonores \cite{valle2009framework, finney2010soundscape}. Le simulateur TAPESTREA \cite{misra_musical_2007} se base sur l'extraction de signaux sonores issus d'enregistrements, la classification de ces signaux (sinusoïdal, transitoire ou bruit de fond) et leur modulation afin de les insérer dans des mixtures sonores. Les fichiers audio modifiés peuvent alors être placés dans une scène sonore soit de manière bouclée, c'est-à-dire qu'un évènement sonore sera placé $N$ fois dans un intervalle de temps, soit plus précisément en situant temporellement son emplacement.
Ces techniques présentent l'avantage de s'appuyer sur des sons réels issus directement d'enregistrements sonores, et non des sons synthétisés ainsi que de permettre la modification des sons extraits selon de nombreux paramètres ainsi que d'avoir une grande maitrise dans la construction des scènes sonores. La limite de cette technique est la phase d'extraction où les évènements sonores doivent soit avoir un rapport $signal/bruit$ élevé, soit ne pas présenter de recouvrement temporel et fréquentiel avec d'autres sources sonores. Sans cela, l'extraction des signaux est moins performante. De plus, dans le but d'obtenir des scènes sonores urbaines, il faut veiller à ne pas trop modifier les objets sonores afin d'éviter l'apparition d'artefacts qui réduiraient leur réalisme.
D'autre simulateurs se basent sur des bases de données de sons pré-existantes comme chez \cite{bruce_development_2009} et \cite{rossignol_simscene_2015}.

Dans l'outil de Bruce et Davies \cite{bruce_development_2009}, l'utilisateur a la possibilité de choisir les sources sonores dans la scène, d'ajuster le niveau sonore et de choisir la position de la source. Leur base de données de sons est issue d'enregistrements audio réalisés par leur soin basé sur un nombre de sources défini selon des précédentes interviews et des marches sonores réalisées. Leur simulateur fut ensuite utilisé dans le cas de la synthèse de scènes sonores urbaines afin de déterminer les classes de sons les plus influentes \cite{davies2014soundscape}.
Enfin le simulateur développé par \cite{lagrange2015evaluation}, \textit{SimScene}, propose à l'utilisateur de gérer un ensemble de paramètres (classe de son, position des évènements, émergence des évènements sonores par rapport au bruit de fond\dots) modélisés par des valeurs moyennes complétées par des écarts-types. 
Cette particularité permet à l'utilisateur soit de définir précisément la position des évènements sonores (\og je veux un sifflement d'oiseaux toutes les 5 secondes \fg{}), soit de générer des variations aléatoires que \textit{SimScene} gère (\og je veux un sifflement d'oiseau toutes les 5 ($\pm$ 2) secondes \fg{}). 
En plus de ces spécificités, cet outil a déjà été utilisé pour des études relatifs au payage sonore \cite{lafay2015approaching} où l'outil permet facilement la création de scènes sonores. \'Egalement, le simulateur a permis la réalisation de corpus de jeu de donnée pour le DCASE challenge \cite{stowell2015detection} dans le cas de la tâche de détection d'évènements sonores \cite{lagrange2015evaluation}. 
En raison de son fonctionnement et de son utilisation déjà éprouvée pour des ESU, le simulateur \textit{SimScene} a été choisi pour réaliser les corpus de scènes sonores urbaines.

\section{Présentation de \textit{SimScene}}
Le logiciel \textit{SimScene} \cite{rossignol_simscene_2015} est un simulateur de scènes sonores \footnote{projet open-source disponible à \url{https://bitbucket.org/mlagrange/simscene}} qui consiste à superposer des \textit{évènements} sonores, issus d'une base de données de sons isolés, à un signal \textit{bruit de fond} qui dure tout le long de l'échantillon. À la différence de l'outil TAPESTRA, la base de données est constituée de sons isolés et non plus construite à partir d'une phase d'extraction. Cette particularité permet d'avoir une grande liberté quant aux sources sonores qu'on peut intégrer. \textit{SimScene} permet de renseigner plusieurs paramètres de hauts niveaux pour réaliser des mixtures sonores :

\begin{itemize}
\item le rapport \textit{évènement/bruit de fond} (abrégé $EBR$ pour \textit{Event Background Ratio}),
\item le temps de présence moyen d'une classe de son,
\item l'occurrence moyenne d'une classe de son dans une scène,
\item l'intervalle temporel $\tau$ entre chaque audio d'une même classe de son,
\item la présence d'un \textit{fade in} et d'un \textit{fade out} pour chaque échantillon.\\
\end{itemize}

Chaque paramètre est également complété par un écart-type qui instaure de la variabilité d'une scène à l'autre. Les sons sont ensuite sélectionnés aléatoirement dans la base de données et positionnés dans la mixture sonore, calibrés selon l'$EBR$ renseigné. En plus d'un audio pour la mixture sonore globale, un audio pour chaque classe de son présent dans la scène est généré permettant de connaitre sa contribution exacte. Ici, ce sont toutes les classes de sons relatifs au trafic routier qui permettent d'estimer son niveau sonore exact, $L_{eq,tr.}$ dans la scène.\\

En parallèle, \textit{SimScene} génère 3 fichiers images (l'évolution temporelle du niveau sonore, le spectrogramme et un \textit{piano Roll} pour visualiser la répartition dans le fichier de chacune des classes, Figure \ref{fig:somefiglabel}), un fichier texte résumant les temps de présence de l'ensemble des sons présents dans la scène et un fichier .mat où se trouve la totalité des résultats et des paramètres de la scène.\\

%\ml{Cette partie manque de rigueur}

\begin{figure}[ht]
\includegraphics[width=5cm]{./figures/SimScene/exemple-timeDomain.pdf}\hfill
\includegraphics[width=5cm]{./figures/SimScene/exemple-pianoRoll.pdf}\hfill
\includegraphics[width=5cm]{./figures/SimScene/exemple-spectrum.pdf}
\caption{Représentation temporelle (à gauche), \textit{Piano Roll} (au centre) et spectrogramme (à droite) générés par \textit{SimScene} d'une scène composée, d'un bruit de fond \textit{trafic} (en vert foncé) et \textit{parc} (en gris) et d'évènements \textit{oiseaux} (en vert), \textit{voiture} (en magenta) et \textit{passant} (en rouge).}\label{fig:somefiglabel}
\end{figure}

La génération de scènes avec \textit{SimScene} peut se faire selon 2 modes. Dans le mode \textit{abstract}, l'utilisateur renseigne lui-même les échantillons sonores présents dans la scène et chaque paramètre permettant de créer des scènes complètement artificiels. Dans le mode \textit{replicate}, le schéma de la scène s'appuie sur un fichier texte où la position des évènements sonores (début et fin) et leurs classes de sons correspondantes sont détaillées. Ce mode permet de reproduire des scènes avec la même organisation temporelle que des enregistrements audio qui ont été annotés.\\

Pour offrir des scènes audio de qualité suffisante, \textit{SimScene} nécessite de posséder une base de données de sons isolés, appelée corpus élémentaire, devant être suffisamment représentatif des sons entendu dans un ESU. De plus, la qualité de chaque audio (rapport Signal/Bruit, échantillonnage) doit être suffisante pour que leurs juxtapositions ne viennent pas détériorer le rendu final. Pour ces travaux, un corpus élémentaire de sons isolés, dédié à l'environnement urbain, a été créé.


\section{Création d'un corpus élémentaire d'échantillons audio}

\subsection{Recherche en ligne des échantillons audio}

La base de données de sons utilisée dans cette étude comprend un ensemble de classes de sons isolés (oiseaux, voiture, klaxon\dots) qui contiennent chacune plusieurs échantillons (\textit{oiseaux01.wav}, \textit{oiseaux02.wav}\dots) pour permettre une grande variabilité dans les mixtures sonores créées. La plupart des échantillons sont trouvés sur des sites en ligne de sons \footnote{\url{www.freesound.org}} \footnote{\url{www.universalsoundbank.com}} et à l'aide de la base de données constituée dans  \cite{salamon_dataset_nodate}. Leur base de données comprend en tout plus de 8000 fichiers audio, collectés également sur le site \textit{freesound.org}, d'une durée inférieure à 4 secondes, répartis en 10 classes de sons : ventilation, klaxon de voiture, enfants qui joue, chien qui aboie, sonnerie, moteur en fonctionnement, coup de feu, marteau-piqueur, sirène et musique dans la rue. L'ensemble des échantillons a été trié afin de ne conserver que les audio ayant un rapport signal à bruit élevé et un échantillonnage de 44,1 kHz. \`A partir de la liste des noms des fichiers originaux fournis avec cette base de données, les fichiers audio sont récupérés dans leur intégralité sur le site internet et intégrés dans la base de données.\\
Afin d'obtenir un rapport signal à bruit acceptable, certains audio ont été filtrés à l'aide du logiciel d'Audacity. D'autres signaux ont, quant à eux, été tronqués ou bien divisés en plusieurs fichiers afin d'en obtenir des durées convenables.

\subsection{Enregistrements de passages de véhicules}\label{part:voiture_record}
S'il est possible de trouver l'ensemble des classes de son avec une qualité suffisante en ligne, dans le cas de la classe \textit{voiture}, étant la source sonore d'intérêt, il était nécessaire de réaliser des enregistrements de passages de véhicules contrôlés sur une piste d'essai afin de posséder un ensemble varié et maitrisé de vitesses et de modèles de véhicules. Pour cela, 2 véhicules à motorisation essence (Renault Mégane, Renault Sénic) et 2 autres à motorisation diesel (Renault Clio, Dacia Sandero) ont été enregistrés en suivant un plan de mesures défini comprenant plusieurs vitesses stabilisées à différents rapports de vitesses ainsi que des phases d'accélération et de freinage du véhicule (voir Tableau \ref{tab:plan_voiture}).

\input{tab/tab_plan_vitesse_voiture}

Les enregistrements ont été réalisés sur la piste d'essais de l'Ifsttar de Nantes le 7 et 8 juillet 2016 à l'aide du système d'acquisition Sound Device 702, la position du microphone a respecté la norme de mesure de bruit au passage S 31-119 et fut donc situé à 7 m de la piste et à une hauteur de 1m50. Enfin, les conditions météorologiques étaient satisfaisantes (temps clair et dégagé, température à l'ombre de 25$\degree$C , vitesse moyenne du vent inférieure à 2 m/s). Les enregistrements sont ensuite extraits en fichiers audio en format .wav échantillonnés à 44,1 kHz.

Afin d'obtenir des échantillons de qualité suffisante, la présence d'oiseaux dans les enregistrements a été atténuée à l'aide d'un filtre médian \cite{fitzgerald_harmonic/percussive_2010} appliqué dans la bande de fréquences $\left[2500 - 6500\right]$ Hz, correspondant aux fréquences d'émission des oiseaux. Ce filtre consiste à définir une fenêtre et à attribuer la valeur médiane de cette fenêtre à l'élément central. Puisque les aspects à la fois temporels et fréquentiels sont à prendre en compte, la fenêtre du filtre est de forme rectangulaire de dimension $5 \times 9$ (96 Hz $\times$ 230 ms). Un exemple de l'application de ce filtre est présenté en Figure \ref{fig:filtre_median}. Même si elle reste persistante sur certains enregistrements, la présence des oiseaux est fortement atténuée sans toutefois dégrader la qualité perceptive du signal global du véhicule.

\begin{figure}[t]
\centering
\includegraphics[width=.9\textwidth]{./figures/autres/filtrageMedian_VL1_R3_40_FR.pdf}
\caption{Zoom du spectrogramme (nombre de point $w = 2^{12}$ avec 50 $\%$ de recouvrement) dans la bande de fréquence $\left[1500-7500 \right]$ Hz d'un enregistrement de passage de véhicule (véhicule Renault, rapport 3, 40 km/h). \`A gauche, l'enregistrement original, à droite l'enregistrement filtré par le filtre médian.}
\label{fig:filtre_median}
\end{figure}


\subsection{Composition du corpus élémentaire complet}

La base de données est alors divisée en deux catégories. Une première comprend les évènements sonores courts allant de 1 seconde (klaxon, aboiement de chien) à plusieurs dizaines de secondes (passages de voitures, sirènes d'ambulances). Ces éléments permettent de générer les évènements sonores émergeant dans une scène. Une seconde catégorie est composée des sons de durées plus longues (1 min à 2 min) qui vont permettre de construire le bruit de fond utile à la création de l'ambiance sonore générale de la scène (chants d'oiseaux continu, voix d'enfants dans une cours de récréation, trafic routier continu\dots).

Les enregistrements des passages de voitures sont, quant à eux, séparés en deux parties : les enregistrements issus des deux  véhicules Renault Mégane et Renault Clio sont inclus dans le corpus élémentaire afin de construire les scènes sonores, les autres échantillons des deux autres voitures (Renault Scénic, Dacia Sandero) serviront dans les chapitres \ref{chap:ambiance} et \ref{chap:grafic} afin de construire le dictionnaire de la NMF et ainsi éviter toute problématique de surapprentissage.
Les échantillons sont ensuite séparés en deux classes de sons : \textit{Voiture Ville} (si la vitesse stabilisée ou finale est inférieure ou égale à 50 km/h) et \textit{Voiture Route} (si la vitesse stabilisée ou finale est supérieure à 50 km/h). L'ensemble des fichiers audio est en format .wav échantillonnés à 44,1 kHz. La base de données finale est résumée dans le Tableau \ref{tab:dataBaseEv} pour les évènements sonores et dans le Tableau \ref{tab:dataBaseBcg} pour les bruits de fond sonores.

\input{tab/tab_base_de_donnee}

La classe de son \textit{bruit rue} résume les nombreux bruits, le plus souvent très bref, dont la source sonore n'a pas pu être déterminée. De la même façon, les sons relatifs à un chantier en construction (marteau-piqueur, marteau, perceuse) sont regroupés en une seule classe par soucis de simplification.
À partir de ce corpus constitué, disponible en ligne\footnote{\url{https://zenodo.org/record/1213793}}, il est possible de réaliser des corpus de scènes sonores urbaines. En vue d'étudier le comportement de la NMF puis d'en évaluer les performances, deux corpus de scènes sonores urbaines sont construits.

\section{Corpus d'évaluation \textit{Ambiance}}
\label{part:corpus_ambiance}
Dans un premier temps le choix est fait de générer un corpus où la présence de chaque source est définie selon sa classe de son et où les niveaux sonores du trafic sont calibrés. Ce corpus a vocation à être utiliser pour étudier le comportement de la NMF selon certaines sources sonores isolées et selon la prédominance du trafic routier dans les scènes. Les étapes impliquées dans la construction de ce corpus sont présentées dans la Figure \ref{fig:bloc_diagram_tir}. Nommé \textit{Ambiance}, ce premier corpus consiste en un ensemble de 6 sous-corpus de 25 scènes $M$ ayant chacune une durée de 30 secondes. Chaque sous-corpus, la mixture sonore $M_i$ mélange une composante \textit{trafic} ($S_{tr.}$) avec une classe de son spécifique (appelée classe \textit{interférante}) ($S_{int.}$), tel que,  

\begin{equation}
M_i = S_{tr.,i}+S_{int.,i}.
\end{equation}

La composante $S_{tr.}$ inclut les évènements sonores appartenant aux classes de sons \textit{Voiture Ville} et \textit{Voiture route}, qui correspondent aux passages des voitures, et les bruits de fond \textit{Trafic Routier}. Le reste est résumé dans la composante interférante $S_{int.}$.

\begin{figure}[ht]
\centering
\includegraphics[width=.9\linewidth]{./figures/autres/TIR_ambiance.pdf}
\caption{Schéma bloc de la pondération du signal trafic selon la scène $i$ et le $TIR$.}
\label{fig:bloc_diagram_tir}
\end{figure}


\begin{table}[h]
\centering
\caption{Résumé des classes de sons inclues dans les classes interférantes, seules les classes \textit{alerte} et \textit{transport} ne contiennent pas de bruit de fond.}
\label{tab:class_inter}
\begin{tabular}{lll}
\toprule
\textbf{Classe interférante}  & \multicolumn{1}{c}{\textbf{\'Evènement}}                                                & \multicolumn{1}{c}{\textbf{Bruit de fond}}  \\
          \toprule
alerte    & \begin{tabular}[c]{@{}l@{}}- Klaxon\\ - Sirène\end{tabular}                  & \multicolumn{1}{c}{-}                                                       \\ \hline
animaux   & \begin{tabular}[c]{@{}l@{}}- Oiseaux\\ - Aboiement de chien\end{tabular}                  & - Oiseaux                                                                   \\ \hline
climat    & - Orage                                                                      & \begin{tabular}[c]{@{}l@{}}- Vent dans les arbres\\ - Pluie\end{tabular}                    \\ \hline
humain    & \begin{tabular}[c]{@{}l@{}}- Voix\\ - Bruit de pas\end{tabular} & - Brouhaha de foule                                                                     \\ \hline
transport & \begin{tabular}[c]{@{}l@{}}- Train\\ - Tramway\\ - Avion\end{tabular}        & \multicolumn{1}{c}{-}                                                       \\ \hline
mécanique & \begin{tabular}[c]{@{}l@{}}- Bruit de rue\\ - Bruit de chantier\end{tabular} & \begin{tabular}[c]{@{}l@{}}- Ventilation\\ - Bruit de chantier\end{tabular}\\
\bottomrule
\end{tabular}
\end{table}

Ces 6 sous-corpus sont résumés dans le Tableau \ref{tab:class_inter} avec les classes de sons inclues qui forment les classes interférantes. Chaque scène comprend un bruit de fond \textit{trafic} ainsi que jusqu'à 5 passages de voiture.
Pour les classes interférantes, leur présence dans chaque scène est systématique. Elle est définie selon un tirage d'une loi uniforme : une valeur aléatoire est tirée, selon sa valeur elle définit la présence ou non de la classe de son. Par exemple, dans le cas de la classe interférante \textit{animaux}, qui comprend 2 classes de sons, il y a 33 $\%$ de chance d'avoir la classe \textit{oiseaux}, 33 $\%$ de chance d'avoir des aboiements et 33 $\%$ de chance d'avoir les deux classes présentes. Pour le cas des signaux \textit{alerte}, comme la durée d'un klaxon est plus brève que celle d'une sirène, la répartition de la distribution est modifiée afin de mieux équilibrer leur présence temporelle (10 $\%$ de chance d'avoir une sirène, 80 $\%$ de chance d'avoir un coup de klaxon et 10 $\%$ d'avoir les deux dans la même scène).
Dans le cas de \textit{climat} et \textit{mécanique}, d'autre bruits de fond peuvent également être présent là aussi équitablement répartit. Enfin pour la classe \textit{humain}, la présence d'une foule en bruit de fond est présente une scène sur deux. 
On résume dans la Figure \ref{fig:spectre_moyen} les spectres moyens sur les 25 scènes du signal des classes \textit{trafic} et \textit{interférant}.

\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{./figures/NMF/spectre_ambiance.pdf}
\caption{Spectres sonores moyens des classes \textit{interférante} (courbes en bleu) et \textit{trafic} (courbes en rouge) pour chaque sous-corpus.}
\label{fig:spectre_moyen}
\end{figure}


Dans le cas des sous-corpus \textit{alerte} et \textit{animaux}, les allures des spectres sont différentes de celles du \textit{trafic} : ce sont des sons plus aigus et harmoniques dont les variations temporelles sont bien spécifiques. Le sifflement d'un oiseau ou le retentissement d'un klaxon sont plus ponctuels que le passage d'un voiture. \`A l'inverse, pour les autres sous-corpus, cette distinction est plus complexe puisque des composantes dans les basses-fréquences sont également présentes.

Chaque scène $i$ générée possède alors un niveau sonore trafic initial $L_{eq,tr.,init.,i}$ et un niveau sonore \textit{interférant}, $L_{eq,int.,i}$. Elles sont ensuite, chacune, dupliquées 5 fois où le niveau sonore du trafic y est calibré tel que, pour une scène $i$, 

\begin{equation}
TIR = L_{eq,tr., tir, i} - L_{eq,interferant, i}
\end{equation}

avec $TIR$ le Rapport des niveaux sonores du trafic et de la classe interférante (\textit{Traffic Interfering Ratio} en anglais) où $TIR \in \lbrace$-12, -6, 0, 6, 12$\rbrace$ dB. Ce $TIR$ s'assimile au rapport \textit{source-interférence} défini dans \cite{vincent2006performance}. Pour cela, les fichiers audio relatifs au trafic sont pondérés par un coefficient $\alpha$ afin d'obtenir le niveau sonore souhaité selon le $TIR$ avec

\begin{equation}
\alpha(TIR,i) = 10^{\sfrac{(TIR_{init,i}-TIR)}{20}}
\end{equation}

où $TIR_{init.,i} = L_{eq,tr.,init.,i}-L_{eq,int.,i}$. Les étapes sont résumées sous la forme d'un schéma bloc dans la Figure \ref{fig:bloc_diagram_tir}. Lorsque $TIR < 0$ dB, le signal trafic est plus faible que le signal interférant, à l'inverse lorsque $TIR>0$, le trafic devient la classe sonore prépondérante. La Figure \ref{fig:exemple_TIR} présente un exemple d'une scène sonore \textit{alerte} pour 3 valeurs du $TIR$.\\

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\linewidth]{./figures/NMF/Lp_TIR.pdf}
\caption{Exemple de l'évolution du niveau sonore équivalent 1 seconde $L_{eq,1s}$ d'une mixture sonore extraite du sous-corpus \textit{alerte} avec la composante trafic calibrée à $TIR \in \lbrace-12, 0, 12\rbrace$ dB.}
\label{fig:exemple_TIR}
\end{figure}


En tout 750 scènes sont ainsi disponibles (6 sous-corpus $\times$ 25 scènes $\times$ 5 $TIR$) pour une durée totale du corpus de 6h30. Les scènes de ce corpus ne peuvent pas être assimilables à des enregistrements sonores réalisés en ville, mais permettront d'étudier le comportement des estimateurs dans le chapitre \ref{chap:ambiance}. 

\section{Corpus d'évaluation de scènes sonores urbaines réalistes}
\label{part:corpus_grafic}

Un second corpus est généré, basé sur des enregistrements sonores réalisés en ville. Ce corpus d'évaluation de Scènes sOnores Urbaines Réalistes (corpus \textit{SOUR}) a pour vocation de tester les performances de la NMF sur des scènes similaires à des enregistrements sonore faits en ville. Pour cela, un corpus de référence constitué d'enregistrements audio est obtenu pour ensuite être écouté et annoté. Ces annotations permettent alors de reproduire ces enregistrements en scènes simulées (dit \textit{répliquées}) qui forment alors le corpus d'évaluation \textit{SOUR}. L'ensemble des étapes est résumé sous forme de bloc dans la Figure \ref{fig:bloc_diagram_annotation}.

\begin{figure}[ht]
\centering
\includegraphics[width=.7\textwidth]{./figures/autres/bloc_diagram_annotation.pdf}
\caption{Schéma bloc résumant la création du corpus d'évaluation de scènes sonores urbaines réalistes \textit{SOUR}.}
\label{fig:bloc_diagram_annotation}
\end{figure}

\subsection{Présentation des enregistrements audio de références}

Les enregistrements audio de références sont issus du projet GRAFIC \cite{aumond2017modeling} et ont été recueillis à pied dans le 13\ieme~arrondissement de la ville de Paris sur un parcours comprenant 19 points d'arrêts (Figure \ref{fig:parcoursGRAFIC}). Le parcours défini présente l'avantage de couvrir plusieurs ambiances sonores représentatives d'un environnement sonore urbain (Tableau \ref{tab:resume19pts}).\\

\begin{figure}[hbtp]
\centering
\includegraphics[width=.7\textwidth]{./figures/grafic/trajet_19pts.png}
\caption{Parcours réalisé avec les 19 points de mesures avec le niveau sonore mesuré équivalent.}
\label{fig:parcoursGRAFIC}
\end{figure}

Ce trajet a été parcouru sur deux jours (le 23/05/2015, jour 1, et le 30/05/2015, jour 2), deux fois par jour (le matin puis l'après-midi) dans un sens (d'est en ouest, EW) et dans l'autre (d'ouest en est, WE). L'enregistrement est réalisé par un système d'acquisition équipé d'un microphone ASASense omnidirectionnel situé sur un sac à dos porté par l'opérateur \cite{aumond2017modeling}. En tout, 76 enregistrements audio (19 points $\times$ 4 trajets) de 1 à 4 minutes sont disponibles. \\

\input{tab/tab_resume_19_points_mesures}


\subsection{Écoutes des scènes sonores}

La première étape a consisté à réaliser une classification à l'écoute (Tableau \ref{tab:classificationScene}), selon quatre ambiances sonores (\textit{Parc}, \textit{Rue calme}, \textit{Rue bruyante}, \textit{Rue très bruyante} \cite{can_describing_2015}), des enregistrements sonores à partir des indications fournies dans \cite{aumond2017modeling} (résumé dans le Tableau \ref{tab:resume19pts}).\\

\input{tab/tab_classification_scene_sonore}

Une majorité de scènes appartiennent à l'ambiance sonore \textit{rue calme} (35 scènes), 23 scènes appartiennent à l'ambiance \textit{rue animée}, 8 scènes à l'ambiance \textit{parc} et 8 scènes à l'ambiance \textit{rue très animée}. Plus de la moitié des points de mesures possèdent la même ambiance sur les 4 trajets. À l'exception du point 10, tous les points de mesures possèdent deux ambiances sonores voisines. Ces variations proviennent de l'évolution des activités dans la journée (matin ou l'après-midi). Enfin, les points 3 et 19 du parcours 1-WE ne sont pas exploitables : le point 3 est pollué par un camion balayeur et le point 19 n'a pas été correctement enregistré. Au final, c'est 74 fichiers audio qui sont disponibles et utilisés pour créer des scènes sonores. Ces 74 enregistrements forment le \textit{corpus de référence}.

\subsection{Annotation des enregistrements sonores}\label{part:scene_annotation}

L'annotation des 74 enregistrements est ensuite réalisée consistant à écouter chaque fichier audio et à estimer la nature des sources sonores présentes ainsi que leur temps de présence. Pour chaque enregistrement, l'ensemble des annotations est résumé dans un fichier texte. Un exemple d'annotation est présenté dans le Tableau \ref{tab:exemple_annotation}.\\

\begin{table}[h]
\caption{Exemple d'un fichier d'annotation pour la scène 1-EW-07.}
\centering
\begin{tabular}{lll}
\toprule
\textbf{évènements}    & $\mathbf{t_{init}}$ \textbf{(s)} & $\mathbf{t_{fin}}$ \textbf{(s)} \\ \midrule
bruit rue     & 0,00            & 8,50           \\
\rowcolor[HTML]{C0C0C0}
voix          & 0,00            & 44,00          \\
camion        & 1,00            & 56,10          \\
\rowcolor[HTML]{C0C0C0}
voix          & 36,50           & 42,30          \\
voiture Ville & 52,00          & 63,00          \\
\rowcolor[HTML]{C0C0C0}
voix          & 59,00           & 66,50         \\ \bottomrule
\end{tabular}
\label{tab:exemple_annotation}
\end{table}

\input{tab/tab_occurence_source_par_ambiance}

De ces annotations, il est possible d'estimer, par ambiance sonore, les sources sonores qui caractérisent leur bruit de fond, les classes de sons des évènements sonores ainsi que leur densité (nombre d'évènement par minute). Ces informations peuvent être utilisées pour pouvoir créer des scènes par le mode \textit{abstract} de \textit{SimScene} (Tableau \ref{tab:obsScene}). Le niveau sonore moyen est une donnée qui est à considérer avec prudence. En effet, le fichier audio de calibration n'a pas été fourni avec les enregistrements. Il n'a pas été possible d'établir avec certitude les niveaux sonores exacts des scènes. Une calibration relative a toutefois été réalisée sur l'ensemble des enregistrements audio avec l'aide des niveaux sonores renseignés par la Figure \ref{fig:parcoursGRAFIC} afin d'obtenir, par scène, des niveaux sonores équivalents.\\

Sur l'ensemble des scènes sonores, 11 classes de sons sont identifiées en tant qu'évènement sonore  (\textit{trafic routier, voix, sifflements d'oiseaux, bruit de rue, bruit de pas, porte de maison, porte de voiture, chantier, klaxon, sonnette, sirène}) et 3 classes de sons sont présentes en tant que bruit de fond sonore (\textit{brouhaha de foule, sifflements d'oiseaux, trafic routier continu}).
Les sources sonores les plus communes sont \textit{voiture}, \textit{voix} et \textit{bruit rue}. En outre, en plus des classes de sons résumées dans le Tableau \ref{tab:obsScene}, de nombreuses autres classes de sons (\textit{aboiement de chien}, \textit{bruit de balais}, \textit{toussotement}, \textit{passage d'avion}, \textit{roulement de valise}) entendues interviennent plus sporadiquement (nombre d'évènement/min < 0,1) et sont susceptibles d'être présentes dans les quatre ambiances sonores.
La composition des environnements sonores diffère naturellement selon les différentes ambiances sonores : dans \textit{Parc} la voix et les oiseaux sont les bruits de fond sonores principaux permettant d'établir l'ambiance sonore adéquate, les sons les plus émergeant sont alors ceux relié à la présence humaine et aux oiseaux. Puis, plus les ambiances sonores sont dominées par la classe \textit{trafic}, moins les émergences sonores sont élevées en raison du fort niveau du bruit de fond sonore \textit{trafic}. Les classes de sons \og naturel \fg{} (\textit{oiseaux)} disparaissent alors progressivement au profit de celles liés aux activités humaines. Dans le cas de l'ambiance sonore \textit{Rue calme}, les émergences sont plus élevées en raison d'un bruit de fond plus faible.
Notons que dans \textit{Rue calme}, \textit{bruyante} et dans \textit{Parc}, le décompte des voitures est assez aisé. Il l'est beaucoup moins dans \textit{rue très animée} où un flot de véhicules peut être présent, le comptage y est alors très délicat car les véhicules peuvent être considérés à la fois comme bruit de fond et évènements sonore.
Sans étude perceptive sur le débit de véhicules à partir duquel les passages de véhicules deviennent un flux, une moyenne de 1 véhicule par seconde est alors considérée comme raisonnable. Un contrôle à l'écoute permet de vérifier que le rendu est satisfaisant. Le rapport nombre d'évènement/min renseigné dans le Tableau \ref{tab:obsScene} est donc soumis à une forte incertitude mais reste cependant cohérent avec les indications du débit moyen fournis dans \cite{aumond2017modeling} ($\approx$ 2000 véhicules/heure). \\

\subsection{Reproduction des enregistrements audio}\label{section:reproductionScene}

Afin d'obtenir des scènes les plus réalistes que possibles, le choix a été fait de reproduire les 74 enregistrements à l'aide de leur annotation et du mode \textit{replicate} de \textit{SimScene}. Ce choix permet ainsi de s'assurer que la disposition des évènements sonores dans les mixtures sonores est la plus proche d'une structure temporelle écologiquement valide. Les durées cumulées par ambiance sonore sont résumées dans la Tableau \ref{tab:resume_sour}. Avec un nombre de scènes plus importante, \textit{rue calme} est naturellement l'ambiance dont la durée cumulée est la plus longue, l'ambiance \textit{parc} étant alors la plus courte.

\begin{table}[h!]
\caption{Durées cumulées par ambiance du corpus \textit{SOUR}.}
\label{tab:resume_sour}
\centering
\begin{tabular}{L{3cm}C{2cm}C{2cm}}
\toprule
\textbf{ambiance sonore}  & \textbf{N} & \textbf{durée (s)}  \\ \toprule
Parc & 8 & 960 \\
Rue calme & 35 & 4636 \\
Rue bruyante & 23 & 3366 \\
Rue très bruyante & 8 & 1285 \\ \midrule
\textbf{total} & 74 & 10 247 \\ \bottomrule
\end{tabular}
\end{table}

La difficulté dans la génération des scènes sonores réside surtout dans l'estimation du \textit{event background ratio} pour les évènements sonores qui doit être cohérent par rapport à l'ambiance souhaitée. La détermination de sa valeur et de la variance correspondante s'est donc faite empiriquement afin d'obtenir un rendu satisfaisant. Pour vérifier que la répartition des sons entre les éléments \textit{trafic} et \textit{interférant} dans chaque scène reste cohérent par rapport à l'ambiance sonore qui lui est assigné, le $TIR$ dans chaque scène est calculé et résumé en Figure \ref{fig:tir_grafic}. La valeur du $TIR$ moyen augmente linéairement avec l'ambiance sonore entre -9 dB et 17 dB. L'évolution du $TIR$ à travers les ambiances traduit correctement la présence de plus en plus forte du trafic. Par ailleurs, la plupart des scènes possèdent un $TIR$ positif et donc une part du trafic plus importante que celle de la classe interférante. Par rapport au corpus \textit{Ambiance}, ce corpus privilégie donc plus des valeurs du $TIR$ positifs. 

\begin{figure}[h]
\centering
\includegraphics[width=.8\linewidth]{./figures/grafic/TIR_grafic.pdf}
\caption{Valeurs du $TIR$ par scène et moyennés par ambiance sonore pour le corpus \textit{SOUR}.}
\label{fig:tir_grafic}
\end{figure}

Les scènes sonores sont ensuite calibrées non pas selon les niveaux sonores des enregistrements qui ont servi à les construire puisque leurs niveaux sonores exacts ne sont pas connus mais selon le niveau sonore moyen par ambiance sonore, résumé dans le Tableau \ref{tab:obsScene}. 
Cet étape n'influe en rien sur la suite de l'étude car les scènes sont construites d'un point de vue relatif, c'est-à-dire que les scènes sonores et l'ambiance auxquelles elles appartiennent ne sont pas liées à leur niveau sonore global mais aux différentes classes de sons présentes et à leurs émergences par rapport au bruit de fond. En vue de déterminer le niveau de bruit du trafic, le facteur déterminant est alors la contribution de cette source sonore dans la scène et non le niveau sonore global de celle-ci. Cette calibration a surtout pour objectif d'homogénéiser les différentes scènes sonores dans chaque ambiance.\\

Dans la suite du document, les scènes issues du mode \textit{replicate} de \textit{SimScene} seront appelées \og scènes répliquées \fg{} en raison du processus de duplication. Les scènes originelles sont, quant à elles, nommées \og scènes enregistrées \fg{}. L'ensemble des ces scènes répliquées forment le \textit{corpus d'évaluation SOUR}. L'annexe \ref{annexe:correspondanceNameSour} résume la correspondance entre le nom des scènes enregistrées, nommées en fonction du jour, du sens du trajet et du point d'enregistrement (par exemple 1-EW-01), et le nom des scènes répliquées, nommées en fonction de l'ambiance sonore auxquelles elles appartiennent et d'un numéro d'identification (par exemple \textit{Parc-01}). \\


\section{Validation du réalisme du corpus d'évaluation \textit{SOUR} par un test perceptif}\label{sec:test}

Afin de vérifier que le rendu global des scènes répliquées est suffisamment réaliste pour qu'elles puissent être assimilables à des enregistrements faits en ville, celles-ci sont soumises à un test perceptif.

\subsection{Mise en place du test}

Ce test consiste à faire écouter à un panel d'auditeurs un ensemble de scènes sonores comprenant autant d'enregistrements sonores que de scènes reconstituées. Pour chaque scène, l'auditeur doit alors évaluer, sur une échelle de Likert à 7 points allant de \og très peu réaliste \fg{} à \og extrêmement réaliste \fg{}, le réalisme de la scène qu'il vient d'entendre. L'hypothèse que nous souhaitons confirmer est que l'ensemble des scènes répliquées sont perçues de façon similaire aux scènes réalistes.
Sur l'ensemble des 148 scènes (74 enregistrées, 74 répliquées), un ensemble de 40 scènes sont testés.
Cet ensemble est composé dans une première moitié de scènes enregistrées choisies aléatoirement parmi les 74 enregistrements tout en prenant soin d'avoir une répartition équitable entre les ambiances sonores afin d'avoir suffisamment de diversité sonore. On extrait alors 5 scènes issues de l'ambiance \textit{Parc}, 6 issues de \textit{Rue calme}, 4 de \textit{Rue bruyante} et 5 de \textit{Rue très bruyante. Pour chaque audio, 30 secondes sont ensuite sélectionnés aléatoirement.
La seconde moitié du corpus est alors composée des mêmes 30 secondes des scènes répliquées respectives. Si l'hypothèse est vérifiée, nous supposerons que si le réalisme de ces 20 scènes répliquées est perçu de la même manière que les 20 scènes enregistrées, celui-ci pourra être étendu aux 54 autres scènes répliquées puisqu'elles sont construites sur le même processus. Un récapitulatif des fichiers audio sélectionnés et de la position des 30 secondes extraites sont résumés dans le Tableau~\ref{tab:resume_scene_test}.\\

\input{tab/tab_40_audio_teste}

Pour limiter les erreurs statistiques dues aux variations de concentration du sujet lorsque les tests sont trop longs, chaque auditeur écoute un sous-corpus de 20 audio ; la durée du test n'excède alors pas 10 minutes. Comme les auditeurs n'évaluent plus l'ensemble des scènes mais seulement une partie, il faut définir un plan d'écoute qui répartit équitablement l'ordre de succession des écoutes. Pour cela, on réalise un plan expérimental en \og Bloc Équilibré Incomplet \fg{} (BEI) \cite{pages_blocs_2007}.
En analyse sensorielle, un BEI permet d'élaborer l'ordre d'évaluation des produits testés pour chaque panéliste en évitant que des biais statistiques apparaissent (effet de rang, du juge, de succession\dots). Il se construit à partir de plusieurs variables :

\begin{itemize}
\item le nombre de blocs $J$ (appelé ici auditeur),
\item le nombre de traitements à tester, $B$ (qui correspondant au nombre total d'extraits sonores dans le test),
\item le nombre de traitements testé par juge, $K$ (qui équivaut au nombre d'écoutes réalisées par chaque auditeur),
\item le nombre de réplications d'un traitement, $R$,
\item le nombre de répétabilités d'une paire de traitement, $\lambda$.\\
\end{itemize}

Plusieurs conditions sont à remplir entre ces variables pour réaliser un BEI correct :

\begin{subequations}\label{BIE_cond}
\begin{align}
B &\geq K, \label{eq:BIE_cond1}\\
JK &= BR, \label{eq:BIE_cond2}\\
\lambda &= R\frac{K-1}{B-1} \label{eq:BIE_cond3}
\end{align}
\end{subequations}

avec $\left[J, B, K, R, \lambda\right] \in \mathbb{N}$.\\

La dénomination \og incomplète \fg{} provient du fait que les juges n'évaluent pas tous les produits testés (condition \ref{eq:BIE_cond1}). La dénomination \og équilibré \fg{}, quant à elle, provient du fait que chaque juge évalue un même nombre de produits ($K$), que ces produits sont évalués un même nombre de fois ($R$) et que toute paire de produits est évaluée un même nombre de fois ($\lambda$). \\

Plusieurs paramètres ont été choisis et justifiés au début de la partie : le nombre d'extraits sonores testé a été établi à 40 ($B = 40$) pour un nombre d'extraits audio évalué par auditeur fixé à 20, ($K = 20$). La principale difficulté reste à obtenir la participation de $J$ personnes pour ce test. Ce nombre est alors fixé à $J = 50$ en cela que ce nombre est suffisant et facilement atteignable en un temps raisonnable. À partir des variables $J$, $B$ et $K$, le nombre $R$ de réplication est fixé à 25. Toutefois, ces valeurs impliquent que la condition \ref{eq:BIE_cond3} n'est pas validée ($\lambda = 9,69 \notin \mathbb{N}$) et donc que les contraintes que l'on s'impose ne permettent pas d'obtenir un plan équilibré. Deux solutions sont alors possibles : la première serait de modifier certains paramètres pour trouver l'équilibre. Or le nombre d'auditeur, $J = 50$, parait un nombre maximal raisonnable à atteindre tout comme le nombre de fichiers audio à tester $K$. Avec ces 2 contraintes fixées, il n'est pas possible d'obtenir un plan d'écoute satisfaisant. La deuxième solution, qui semble alors la plus adaptée, est de réaliser un plan optimal \cite{pages_blocs_2007}. Dans ce cas, pour une configuration $\left[J, K, B\right]$ donnée, un algorithme d'échange détermine un \og plan optimal \fg{} qui satisfait le plus possible son équilibre (sans toutefois l'atteindre parfaitement). En d'autres termes, cet algorithme permet de déterminer la suite de produits testés par chaque juge qui permettra de respecter au mieux les conditions \ref{BIE_cond}.
Le plan optimal $X_{opt}$ en fonction des conditions $J$, $K$ et $R$ est réalisé sous le logiciel \textit{R} à l'aide la fonction \textit{optimaldesign} fourni par le package \textit{SensoMineR} \cite{le_sensominer_2008}.


\begin{figure}[h]
\centering
\includegraphics[width=.7\linewidth]{./figures/test_perceptif/repartition-real-simulated.pdf}
\caption{Distribution des scènes audio pour chaque juge selon leur type (enregistré ou répliqué) : en bleu la quantité de scènes enregistrées évaluées par le juge et en rouge le nombre de scènes répliquées. La somme de ces deux parties équivaut au nombre de scènes testées $K$ par juge.}
\label{fig:repartitionScene}
\end{figure}

Le plan obtenu correspond alors à l'ordre d'écoutes des scènes audio pour chaque juge. Avec ce plan, chaque juge écoute un mélange de scènes enregistrées et répliquées qui n'est pas nécessairement identique. Si la plupart des auditeurs écoutent un même nombre de scènes enregistrées et répliquées, d'autres sont susceptibles d'écouter plus de scènes d'un type que d'un autre. Au maximum, certain juges écoutent 8 scènes d'un type et 12 scènes d'un autre (Figure \ref{fig:repartitionScene}). 
De ce mélange, les auditeurs, durant le test d'écoute, n'évaluent donc pas nécessairement une scène enregistrée et sa version répliquée. 
L'optimisation du plan ne permet également pas d'avoir un nombre de réplication $R$ constant sur l'ensemble des scènes testées mais variable évoluant dans l'intervalle $\left[20,30 \right]$ (Figure~\ref{fig:replication}). \\


\begin{figure}[ht]
\centering
\includegraphics[width = 0.7\textwidth]{./figures/test_perceptif/nb_replication.pdf}
\caption{Nombre de réplication, $R$, pour chaque scène obtenu dans $X_{opt}$ avec comme combinaison $J = 50$, $B = 40$, $K = 20$. Les 20 premières scènes sont les scènes issues des enregistrements du projet GRAFIC, les 20 suivantes sont les scènes répliquées sous \textit{SimScene}.}
\label{fig:replication}
\end{figure}

Une page web \footnote{http://soundthings.org/research/xpRealism} est mis en ligne le 8 février 2017 permettant l'accès au test à un large public et s'est clôturé 12 jours plus tard. Chacun des 50 auditeurs écoute donc une succession de 20 extraits audio de 30 secondes dans un ordre établi par le plan optimal. Il leur est demandé de réaliser de test sur des enceintes ou un casque audio de qualité suffisante. Après avoir écouté chaque extrait de 30 secondes, l'auditeur doit répondre à la question \og La scène que vous venez d'entendre vous semble t-elle réaliste ? \fg{} en donnant une note entre 1 et 7. Chaque audio peut être réécouté autant de fois que voulu avant d'être évalué sans qu'il soit toutefois possible de revenir sur son évaluation. L'auditeur a également la possibilité de laisser un commentaire sur chaque audio pour justifier son choix. En fin de test, afin de connaitre le panel d'évaluateur, il leur est demandé de renseigner leur âge, leur sexe (H/F) et leur expérience quant à l'écoute de mixtures sonores urbaines.\\

Les fichiers résultats sont stockés également sous une page web \footnote{http://soundthings.org/research/xpRealism/responses/} et téléchargeables sous le format .json pour ensuite être traités sous le logiciel Matlab.\\

\subsection{Résultats}

L'ensemble des résultats est soumis à différents tests statistiques afin de comparer les évaluation des scènes enregistrées et répliquées.

\subsubsection{Constitution du panel}

La Figure \ref{fig:panelTest} résume, sous forme d'histogrammes, l'âge, le sexe et l'expérience des 50 auditeurs ayant participé au test. 2 personnes n'ont renseigné aucun de ces champs et une troisième personne a seulement omis de préciser son genre. Le panel est composé à 62 $\%$ d'hommes et à 32 $\%$ de femmes. La classe d'âge $\left[20,30\right[$ est la plus représentée suivie de la classe $\left[30,40\right[$ (26 $\%$), $\left[50,60\right[$ (18 $\%$), $\left[40,50\right[$ ($10\%$) et enfin de la classe $>60$ (4 $\%$) . 62 $\%$ du panel a déclaré n'avoir pas d'expérience dans l'écoute d'ambiances sonores urbaines.\\

\begin{figure}[ht]
\centering
\includegraphics[width = .8\textwidth]{./figures/test_perceptif/testPerceptif_panel.pdf}
\caption{Résumé des informations relatifs aux auditeurs.}
\label{fig:panelTest}
\end{figure}



\subsubsection{Distribution des notes des scènes enregistrées et répliquées} 

Dans un premier temps, la distribution de toutes les notes de réalisme données par les auditeurs selon leur type (enregistrées et répliquées) est exprimée au travers d'un diagramme de type \og boîte à moustache \fg{} (Figure \ref{fig:ANOVA_scene}). Cette représentation graphique permet de comparer plusieurs distributions en résumant pour chaque boîte la médiane (trait plein rouge), les valeurs du  premier quartile au troisième quartile (boîte en bleue), la valeur maximale et minimale de la distribution (respectivement trait supérieur et inférieur en noir). \`A cela est également ajoutée la moyenne.\\

\begin{figure}[h]
\centering
\includegraphics[width = 0.8\textwidth]{./figures/test_perceptif/testPerceptif_boxplotType.pdf}
\caption{Représentation en diagramme en boîte à moustache entre les scènes enregistrées et répliquées.}\label{fig:ANOVA_scene}
\end{figure}

La répartition des notes pour les deux types de scènes est fortement similaire. Chaque type présente des valeurs identiques (médiane, valeurs extrêmes, quantiles). Seule la note moyenne permet de différencier les deux ensembles ($m_{En}$ = 4,93 ($\pm$ 1,64) et $m_{Re}$ = 5,06 ($\pm$ 1,56)) où la note moyenne des scènes répliquées est légèrement supérieure.\\

Afin d'étudier l'effet du type de scène sur le réalisme perçu, une analyse scène par scène est nécessaire (les différences de réalisme pouvant se compenser entre les scènes lors d'une analyse globale). Pour cela, un test $t$ de Student est considéré pour chaque scène entre les notes du type \textit{enregistrée} et du type \textit{répliquée}. Un test de Student consiste à comparer les moyennes de 2 groupes d'échantillons pour déterminer si elles sont significativement différentes d'un point de vue statistique. Toutefois, puisque pour chaque scène, les évaluations entre le pendant \textit{enregistré} et \textit{répliqué} sont réalisées par des individus différents, que le nombre d'évaluations par catégorie n'est pas identique et que les variances entre les deux catégories ne sont pas forcément égales, c'est une variante du test-$t$ de Student qui est réalisée : le test-$t$ de Welch \cite{ruxton2006unequal}. Dans ce test, pour chaque scène, deux hypothèses sont émises sur les distributions :

\begin{itemize}
\item les distributions des échantillons des deux catégories sont semblables (hypothèse \textit{nulle} $H_0$),
\item les deux distributions sont différentes, (hypothèse \textit{alternative} $H_1$).\\
\end{itemize}

La statistique $t$ est alors calculée :
\begin{equation}
t = \frac{\bar{X}_1-\bar{X}_2}{\sqrt{\frac{s_1^2}{N_1}+\frac{s_2^2}{N_2}}},
\end{equation}

où $\bar{X}_i$, $s_i$ et $N_i$ sont, respectivement, la moyenne de l'échantillon, la variance et le nombre d'échantillons de la catégorie $i$ ainsi que les degrés de liberté ($DDL$) du système :  

\begin{equation}
DDL = \frac{\left(\frac{s_1^2}{N_1}+\frac{s_2^2}{N_2} \right)^2}{\frac{s_1^4}{N_1^2(N_1-1)}+\frac{s_2^4}{N_2^2(N_2-1)}}.
\end{equation}

La statistique $t$ avec le nombre de degrés de libertés (correction de Welch) sont alors utilisés avec une loi de Student pour déterminer la valeur de la probabilité $p$ (valeur $p$) qui permet de rejeter (ou non) l'hypothèse $H_0$ selon une valeur seuil de référence $\alpha$ (défini à 5 $\%$) :

\begin{itemize}
\item si $p < \alpha$, les distributions considérées sont différentes, l'hypothèse $H_0$ est rejetée et $H_1$ est acceptée,
\item si $p > \alpha$, l'hypothèse $H_0$ est acceptée, les distributions d'où sont issues les évaluations sont considérées identiques.\\
\end{itemize}

Par soucis de concision, seul l'ensemble des 20 valeurs $p$ calculées et les boites à moustaches de chaque scène sont résumés dans les Figures \ref{tab:test-student} et \ref{fig:boxplot_scene}.

\begin{table}[h!]
\caption{DDL, valeurs $t$ et valeurs $p$ pour chaque test de Student mené entre les scènes enregistrées et répliquées; en gras, les valeur $p$ supérieures au seuil de signification de 5 $\%$.}
\label{tab:test-student}
\begin{tabular}{L{1.5cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}}
\toprule
scène & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\toprule
\textbf{DDL} & 48 & 51 & 51 & 51 & 51 & 57 & 57 & 60 & 60 & 60 \\
\rowcolor[HTML]{C0C0C0}
\textbf{valeur} $\mathbf{t}$ & 1,03 & 0,21 & 0,44 & 1,02 & 2,13 & 1,30 & 1,54 & 0,45 & 0,85 & 1,01 \\
\textbf{valeur} $\mathbf{p}$ & \textbf{0,15} & \textbf{0,42} & \textbf{0,33} & \textbf{0,16} & 0,02 &\textbf{0,10} & \textbf{0,06} & \textbf{0,32} & \textbf{0,20} & \textbf{0,16} \\
\bottomrule
\end{tabular}
\begin{tabular}{L{1.5cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}C{1cm}}
\toprule
scène & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 \\
\toprule
DDL & 60 & 60 & 60 & 60 & 60 & 60 & 60 & 60 & 60 & 60 \\
\rowcolor[HTML]{C0C0C0}
valeur $t$ & 0,29 & 0,39 & 1,15 & 0,30 & 0,84 & 0,32 & 0,82 & 2,20 & 0,24 & 0,45 \\
valeur $p$ & \textbf{0,38} & \textbf{0,35} & \textbf{0,13} & \textbf{0,38} & \textbf{0,20} & \textbf{0,37} & \textbf{0,21} & 0,01 & \textbf{0,40} & \textbf{0,33}\\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\subfigure[\label{fig:boxplotEnreg}]{\includegraphics[width=0.7\linewidth]{./figures/test_perceptif/boxplotSceneEnregistree.pdf}}
\subfigure[\label{fig:boxplotRepli}]{\includegraphics [width=0.7\linewidth]{./figures/test_perceptif/boxplotSceneRepliquee.pdf}}

\begin{tabular}{|p{1.5cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2cm}|l|p{0.001cm}|p{2.75cm}|l|}
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
Parc & {\cellcolor[HTML]{5AB25A}} & & Rue calme & {\cellcolor[HTML]{FFCB2F}} & & Rue animée & {\cellcolor[HTML]{F56B00}} & &  Rue très animée & {\cellcolor[HTML]{9A0000}}\\
\hhline{|-|-|~|-|-|~|-|-|~|-|-|}
\end{tabular}

\caption{Boites à moustaches pour les scènes enregistrées  \subref{fig:boxplotEnreg} et pour les scènes répliquées \subref{fig:boxplotRepli} classées selon leur ambiance sonore.}
\label{fig:boxplot_scene}
\end{figure}

L'ensemble des tests de Student mené sur les 20 couples de scènes révèlent des valeurs $p$ inférieures au seuil de signification $\alpha$ de 5 $\%$ pour seulement 2 scènes (scène 5 et 18). Ces résultats sont à mettre en parallèle avec la distribution des notes de ces scènes en Figure \ref{fig:boxplot_scene}. Dans le cas de la scène 5, on observe que le réalisme moyen de la scène répliquée est plus important que celui de la scène enregistrée (Figure \ref{fig:boxplotEnreg}). À l'écoute, la scène 5 issue de l'enregistrement est une scène calme avec peu d'évènements émergents et un bruit de fond, lui aussi, très calme. Il peut être supposé que sans identification claire d'évènements sonores, les auditeurs ont jugé le réalisme de la scène enregistrée moins correctement que sa version répliquée qui, elle, si elle possède aussi peu d'évènements, par son aspect simulé, parait toutefois plus identifiable.
Enfin, pour la scène 18, les deux distributions sont toutes deux situées vers des notes élevées. Mais dans le cas de sa version enregistrée (Figure \ref{fig:boxplotRepli}), la distribution également plus large que la scène répliquée génère une valeur $p$ sous le seuil de signification. Ainsi, malgré un test de Student qui validerait l'hypothèse $H_1$, on peut toute de même considérer que le réalisme des scènes répliquées 5 et 18 est satisfaisant au regard de la distribution de leur notes.
Sur les 18 autres scènes , l'hypothèse $H_0$ n'est donc pas rejetée : le réalisme perçu des scènes testées du type \textit{répliquée} n'est pas significativement différent de celui des scènes \textit{enregistrées}. L'influence de l'évaluation des juges et l'influence de l'ambiance sonore sur le réalisme perçu sont observés, en complément, en Annexe \ref{annexe:anova}, à travers des analyses de variances (ANOVA).

Enfin, il est intéressant d'étudier les commentaires laissés par les auditeurs sur plusieurs scènes. Ces derniers relèvent notamment des sons trop forts ou qui s'inscrivent mal dans les scènes (par exemple oiseaux trop forts dans la scène 21, bruits de pas trop fort dans la scène 24). Enfin certains extraits de voix ne sont pas suffisamment réalistes. En effet, lors de la phase d'écoutes des enregistrements, on remarque que les voix perçues, en dehors d'un brouhaha de foule, sont le plus souvent des bribes de conversations entre deux personnes ou au téléphone. Malheureusement, il n'a pas été possible de trouver des bases de données libres de conversations suffisamments réalistes pour être inclus dans les scènes. De nombreuses bases de données se concentrent, par exemple, sur la lecture de textes récités \cite{el2011survey, kominek2004cmu, barker2015third} ce qui ne permet pas d'atteindre le réalisme souhaité. Les extraits de voix présents dans le corpus élémentaire sont des sons trouvés par défauts, brefs ("hello", "how are you ?") et qui diffèrent beaucoup des voix entendues en ville.
Certains commentaires ont toutefois été laissé sur des scènes enregistrées : pour la scène 4, un auditeur trouve le sifflement des oiseaux trop fort \og artificiel \fg ou dans la scène 8, un auditeur déclare que le trop grand nombre d'évènements sonores nuit au réalisme de la scène. Ces commentaires permettent alors de relativiser ceux laissés sur les scènes répliquées.

En conclusion, sur l'ensemble du corpus testé, il y a une similarité du réalisme perçu par l'ensemble des participants entre les scènes enregistrées et répliquées. Même s'il y a des disparités entre les distributions des notes, l'évaluation du réalisme selon les types de scènes et les ambiances restent similaires (les notes restent comprises entre 4 et 6). 
Certains sons dans les scènes répliquées sembleraient toutefois mal calibrés, ce qui, sur certaines scènes, impactent leur note (la scène 24 par exemple, voir Figure \ref{fig:boxplotRepli}). Mais on retrouve également ce phénomène dans les scènes réelles, ce qui viendrait à relativiser cette mauvaise calibration.
En conséquence, le réalisme perçu des scènes répliquées est considéré comme similaire à celles des scènes réalistes. 
De ces résultats, comme l'ensemble des scènes répliquées est réalisés avec le même dispositif, on généralise ce résultat à l'ensemble du corpus élémentaire \textit{SOUR}.\\

\section{Conclusion du chapitre}
Le logiciel de simulation de scènes audio \textit{SimScene} a été utilisé afin de constituer deux corpus de scènes sonores urbaines. Cette élaboration a nécessité la construction d'un corpus élémentaire qui contient des évènements sonores isolés (sifflement d'oiseaux, aboiement de chien, klaxon\dots{}) ainsi que des bruits de fonds (bruit de trafic routier continu, brouhaha de voix\dots{}). Puisque le trafic routier est la source sonore d'intérêt, des passages de voitures ont été enregistrés sur pistes afin d'obtenir des échantillons audio de qualité suffisante.
De cette base de données, un premier corpus a été élaboré : le corpus d'évaluation \textit{Ambiance}. Il comprend en tout 750 scènes de 30 secondes et se divise en 6 sous-corpus qui sont caractérisés par une classe de son générique (\textit{alerte}, \textit{animaux}, \textit{climat}, \textit{humains}, \textit{transport} et \textit{mécanique}. Chaque sous-corpus est composé de 25 scènes mixant un signal audio trafic avec un signal audio de la classe de son générique, appelée classe de son \textit{interférante}. Chaque scène est alors dupliquée 5 fois où le niveau sonore du trafic est calibré selon celui de la classe de son interférante.
Ce corpus a pour objectif de tester le comportement de la NMF suivant les classes de sons interférantes et des contributions du trafic différentes.
Un second corpus a ensuite été élaboré, le corpus d'évaluation de Scènes Sonores Urbaines Réalistes\textit{SOUR}, qui est la transcription d'enregistrements sonores urbains en scènes simulées. Afin d'estimer la qualité de ces scènes et notamment leur réalisme, une partie de ce corpus a été soumise à un test perceptif qui a révélé que les scènes simulées étaient perçues de façon similaires à des enregistrements audio. Les conclusions de ce test sont alors étendus à l'ensemble du corpus construit. L'intérêt de ce critère de réalisme est de pouvoir assimiler ces scènes à des enregistrements audio et ainsi d'estimer les erreurs que générerait la NMF sur de telles mixtures. Ce corpus a aussi pour vocation à servir l'ensemble des communautés scientifiques développant des outils de reconnaissance, de détection ou de séparation de sources dans un milieu urbain. 


%\bibliographystyle{unsrt}
%\bibliography{../bibliographie}
%
%\end{document}
